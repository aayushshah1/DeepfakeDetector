{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f451f63d",
   "metadata": {},
   "source": [
    "# Deepfake Detection using Deep Feature Stacking and Meta-Learning\n",
    "\n",
    "## Implementation of the research paper:\n",
    "- Paper: **Deepfake Detection using Deep Feature Stacking and Meta-Learning**\n",
    "- Authors: Gourab Naskar, Sk Mohiuddin, Samir Malakar, Erik Cuevas, Ram Sarkar\n",
    "\n",
    "This notebook implements a deepfake detection method using:\n",
    "- Xception - Extracts deep features from images\n",
    "- EfficientNet-B7 - Extracts additional feature representations\n",
    "- Feature Selection - Ranking-based selection to reduce redundant features\n",
    "- Meta-Learner (MLP) - Uses selected features to classify Real vs Fake videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (use -q flag to suppress output)\n",
    "!pip install -q tensorflow keras scikit-learn tqdm matplotlib seaborn pandas numpy\n",
    "!pip install -q opencv-python-headless\n",
    "!pip install -q efficientnet\n",
    "\n",
    "# Check for GPU availability\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "\n",
    "# Enable memory growth for GPU to avoid OOM errors\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "    print(f\"Memory growth enabled on {len(physical_devices)} GPU(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2833537",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import all the libraries needed for the project, including TensorFlow, NumPy, Pandas, and Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da478c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input as xception_preprocess\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# For feature selection and meta-learner\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060507b5",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Load the dataset from a Google Drive link or a public URL, ensuring compatibility with Colab's file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract dataset\n",
    "!wget https://deep-fake-dataset.s3.eu-north-1.amazonaws.com/PreprocessedDatasetV1.zip -O dataset.zip\n",
    "!unzip -q dataset.zip -d /content\n",
    "\n",
    "# Define dataset paths\n",
    "train_dir = '/content/PreprocessedDatasetV1/train'\n",
    "test_dir = '/content/PreprocessedDatasetV1/test'\n",
    "val_dir = '/content/PreprocessedDatasetV1/validation'\n",
    "\n",
    "# Check if directories exist\n",
    "!ls -la /content/PreprocessedDatasetV1\n",
    "print(f\"Train directory exists: {os.path.exists(train_dir)}\")\n",
    "print(f\"Test directory exists: {os.path.exists(test_dir)}\")\n",
    "print(f\"Validation directory exists: {os.path.exists(val_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4975e12",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "Perform data preprocessing steps such as resizing images, normalizing pixel values, and splitting the dataset into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8411a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMAGE_SIZE = 224  # Standard size for many CNNs\n",
    "BATCH_SIZE = 32   # Adjust based on your GPU memory\n",
    "EPOCHS = 20       # Can be reduced with early stopping\n",
    "FEATURE_PERCENTAGE = 30  # Top k% features to keep (as per paper)\n",
    "\n",
    "# Data generators with proper preprocessing for Xception and EfficientNetB7\n",
    "# Training data with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=xception_preprocess,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation and test data only need preprocessing, not augmentation\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=xception_preprocess)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=xception_preprocess)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Check dataset sizes\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")\n",
    "print(f\"Testing samples: {test_generator.samples}\")\n",
    "print(f\"Class indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d36091",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "Define the deep learning model architecture using TensorFlow or PyTorch, ensuring modularity and clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1230c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, img_size):\n",
    "    \"\"\"Create and compile the CNN model\"\"\"\n",
    "    if model_name == 'xception':\n",
    "        # Create the Xception model directly with the right input shape\n",
    "        base_model = Xception(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(img_size, img_size, 3)\n",
    "        )\n",
    "        \n",
    "    elif model_name == 'efficientnet':\n",
    "        # Create EfficientNetB7 model directly with the right input shape\n",
    "        base_model = EfficientNetB7(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(img_size, img_size, 3)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not supported\")\n",
    "    \n",
    "    # Add custom classification head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Freeze the base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Create Xception and EfficientNetB7 models\n",
    "print(\"Creating Xception model...\")\n",
    "xception_model, xception_base = create_model('xception', IMAGE_SIZE)\n",
    "\n",
    "print(\"Creating EfficientNetB7 model...\")\n",
    "efficientnet_model, efficientnet_base = create_model('efficientnet', IMAGE_SIZE)\n",
    "\n",
    "# Print model summaries\n",
    "print(\"\\nXception Model Summary:\")\n",
    "xception_model.summary()\n",
    "\n",
    "print(\"\\nEfficientNetB7 Model Summary:\")\n",
    "efficientnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e680f338",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Train the model on the preprocessed dataset, including callbacks for early stopping and saving the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647483f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_fine_tuning(model, base_model, train_gen, valid_gen, model_name, epochs=EPOCHS):\n",
    "    \"\"\"Train model with two-phase fine tuning strategy\"\"\"\n",
    "    # Define callbacks\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        f'{model_name}_best_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_accuracy', \n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    callbacks = [checkpoint, early_stop, reduce_lr]\n",
    "    \n",
    "    # Phase 1: Initial training with frozen base model\n",
    "    print(f\"Training {model_name} - Phase 1: Training only top layers\")\n",
    "    history1 = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=valid_gen,\n",
    "        epochs=epochs // 2,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # Phase 2: Unfreeze some layers for fine-tuning\n",
    "    if model_name == 'xception':\n",
    "        for layer in base_model.layers[-30:]:  # Unfreeze last 30 layers\n",
    "            layer.trainable = True\n",
    "    else:  # efficientnet\n",
    "        for layer in base_model.layers[-50:]:  # Unfreeze last 50 layers\n",
    "            layer.trainable = True\n",
    "    \n",
    "    # Recompile with lower learning rate\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),  # Lower learning rate for fine-tuning\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(f\"Training {model_name} - Phase 2: Fine-tuning\")\n",
    "    history2 = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=valid_gen,\n",
    "        epochs=epochs // 2,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # Combine histories\n",
    "    combined_history = {}\n",
    "    for key in history1.history.keys():\n",
    "        combined_history[key] = history1.history[key] + history2.history[key]\n",
    "    \n",
    "    return model, combined_history\n",
    "\n",
    "# Train both models with fine-tuning\n",
    "print(\"\\n==== Training Xception Model ====\")\n",
    "xception_model, xception_history = train_model_with_fine_tuning(\n",
    "    xception_model, xception_base, train_generator, val_generator, 'xception'\n",
    ")\n",
    "\n",
    "# Clear memory before training next model\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"\\n==== Training EfficientNetB7 Model ====\")\n",
    "efficientnet_model, efficientnet_history = train_model_with_fine_tuning(\n",
    "    efficientnet_model, efficientnet_base, train_generator, val_generator, 'efficientnet'\n",
    ")\n",
    "\n",
    "# Plot training history for both models\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'{model_name} Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training histories\n",
    "plot_training_history(xception_history, 'Xception')\n",
    "plot_training_history(efficientnet_history, 'EfficientNetB7')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351118ca",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Create feature extractors from the trained models and extract deep features from the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c71d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_extractor(model_name, img_size):\n",
    "    \"\"\"Create a feature extractor model\"\"\"\n",
    "    if model_name == 'xception':\n",
    "        base_model = Xception(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(img_size, img_size, 3),\n",
    "            pooling='avg'\n",
    "        )\n",
    "        return base_model\n",
    "        \n",
    "    elif model_name == 'efficientnet':\n",
    "        base_model = EfficientNetB7(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(img_size, img_size, 3),\n",
    "            pooling='avg'\n",
    "        )\n",
    "        return base_model\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not supported\")\n",
    "\n",
    "def extract_features(feature_extractor, data_generator, name):\n",
    "    \"\"\"Extract features from a dataset using the given extractor\"\"\"\n",
    "    print(f\"Extracting features using {name}...\")\n",
    "    features = []\n",
    "    labels = []\n",
    "    batch_count = 0\n",
    "    total_batches = len(data_generator)\n",
    "    \n",
    "    for batch_x, batch_y in tqdm(data_generator, total=total_batches):\n",
    "        batch_features = feature_extractor.predict(batch_x, verbose=0)\n",
    "        features.append(batch_features)\n",
    "        labels.append(batch_y)\n",
    "        batch_count += 1\n",
    "        \n",
    "        # Stop when we've gone through the entire dataset\n",
    "        if batch_count >= total_batches:\n",
    "            break\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    print(f\"{name} features shape: {features.shape}\")\n",
    "    print(f\"{name} labels shape: {labels.shape}\")\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# Create feature extractors\n",
    "print(\"Creating feature extractors...\")\n",
    "xception_extractor = create_feature_extractor('xception', IMAGE_SIZE)\n",
    "efficientnet_extractor = create_feature_extractor('efficientnet', IMAGE_SIZE)\n",
    "\n",
    "# Reset generators for feature extraction (shuffle=False to maintain order)\n",
    "train_gen_features = ImageDataGenerator(preprocessing_function=xception_preprocess).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Important: keep order of samples\n",
    ")\n",
    "\n",
    "val_gen_features = ImageDataGenerator(preprocessing_function=xception_preprocess).flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen_features = ImageDataGenerator(preprocessing_function=xception_preprocess).flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Extract features for train set\n",
    "train_xception_features, train_labels = extract_features(xception_extractor, train_gen_features, 'Train Xception')\n",
    "\n",
    "# Reset generator for EfficientNet\n",
    "train_gen_features = ImageDataGenerator(preprocessing_function=xception_preprocess).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_efficientnet_features, _ = extract_features(efficientnet_extractor, train_gen_features, 'Train EfficientNet')\n",
    "\n",
    "# Extract features for validation set\n",
    "val_xception_features, val_labels = extract_features(xception_extractor, val_gen_features, 'Val Xception')\n",
    "\n",
    "# Reset generator for EfficientNet\n",
    "val_gen_features = ImageDataGenerator(preprocessing_function=xception_preprocess).flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_efficientnet_features, _ = extract_features(efficientnet_extractor, val_gen_features, 'Val EfficientNet')\n",
    "\n",
    "# Extract features for test set\n",
    "test_xception_features, test_labels = extract_features(xception_extractor, test_gen_features, 'Test Xception')\n",
    "\n",
    "# Reset generator for EfficientNet\n",
    "test_gen_features = ImageDataGenerator(preprocessing_function=xception_preprocess).flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_efficientnet_features, _ = extract_features(efficientnet_extractor, test_gen_features, 'Test EfficientNet')\n",
    "\n",
    "# Stack features\n",
    "train_features = np.concatenate([train_xception_features, train_efficientnet_features], axis=1)\n",
    "val_features = np.concatenate([val_xception_features, val_efficientnet_features], axis=1)\n",
    "test_features = np.concatenate([test_xception_features, test_efficientnet_features], axis=1)\n",
    "\n",
    "print(f\"Stacked feature shapes - Train: {train_features.shape}, Val: {val_features.shape}, Test: {test_features.shape}\")\n",
    "\n",
    "# Clear memory\n",
    "del xception_extractor, efficientnet_extractor\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f6000",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "Use XGBoost and Random Forest to select the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667409be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(train_features, train_labels, val_features, test_features, feature_percentage=FEATURE_PERCENTAGE):\n",
    "    \"\"\"Select top k% features using RandomForest and XGBoost feature importance\"\"\"\n",
    "    print(f\"Starting feature selection... Selecting top {feature_percentage}% features\")\n",
    "    \n",
    "    # Feature selection using Random Forest\n",
    "    print(\"Training Random Forest for feature importance...\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rf.fit(train_features, train_labels)\n",
    "    rf_importances = rf.feature_importances_\n",
    "    \n",
    "    # Feature selection using XGBoost\n",
    "    print(\"Training XGBoost for feature importance...\")\n",
    "    xgb = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, \n",
    "                       eval_metric='logloss', n_jobs=-1)\n",
    "    xgb.fit(train_features, train_labels)\n",
    "    xgb_importances = xgb.feature_importances_\n",
    "    \n",
    "    # Average feature importances and select top k%\n",
    "    average_importances = (rf_importances + xgb_importances) / 2\n",
    "    k = int(feature_percentage * len(average_importances) / 100)\n",
    "    \n",
    "    # Get indices of top k% features\n",
    "    top_k_indices = np.argsort(average_importances)[-k:]\n",
    "    \n",
    "    print(f\"Selected {k} features out of {len(average_importances)} ({feature_percentage}%)\")\n",
    "    \n",
    "    # Create a feature mask for visualization\n",
    "    feature_mask = np.zeros(len(average_importances), dtype=bool)\n",
    "    feature_mask[top_k_indices] = True\n",
    "    \n",
    "    # Visualize top feature importance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(k), average_importances[top_k_indices], color='skyblue')\n",
    "    plt.title(f'Top {k} Feature Importance')\n",
    "    plt.xlabel('Feature Index (sorted by importance)')\n",
    "    plt.ylabel('Average Importance Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Apply feature selection to datasets\n",
    "    train_selected = train_features[:, top_k_indices]\n",
    "    val_selected = val_features[:, top_k_indices]\n",
    "    test_selected = test_features[:, top_k_indices]\n",
    "    \n",
    "    return train_selected, val_selected, test_selected, top_k_indices\n",
    "\n",
    "# Apply feature selection\n",
    "train_features, val_features, test_features, selected_indices = select_features(\n",
    "    train_features, train_labels, val_features, test_features, FEATURE_PERCENTAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd08dafb",
   "metadata": {},
   "source": [
    "# Meta-Learner\n",
    "Train a Meta-Learner (MLP) to classify Real vs Fake videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd767011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_meta_learner(train_features, train_labels, val_features, val_labels):\n",
    "    \"\"\"Train MLP meta-learner on selected features\"\"\"\n",
    "    print(\"Training meta-learner (MLP)...\")\n",
    "    \n",
    "    # Create MLP classifier with optimal architecture for deepfake detection\n",
    "    meta_learner = Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(train_features.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    meta_learner.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Define callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_accuracy',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train the meta-learner\n",
    "    history = meta_learner.fit(\n",
    "        train_features, train_labels,\n",
    "        validation_data=(val_features, val_labels),\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr]\n",
    "    )\n",
    "    \n",
    "    return meta_learner, history\n",
    "\n",
    "# Train the meta-learner\n",
    "meta_learner, meta_history = train_meta_learner(train_features, train_labels, val_features, val_labels)\n",
    "\n",
    "# Plot meta-learner training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(meta_history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(meta_history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Meta-Learner Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(meta_history.history['loss'], label='Training Loss')\n",
    "plt.plot(meta_history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Meta-Learner Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad0836",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n",
    "Evaluate the model's performance on the test dataset and visualize metrics such as accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05efa310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_meta_learner(model, X_test, y_test):\n",
    "    \"\"\"Evaluate meta-learner on test set with comprehensive metrics\"\"\"\n",
    "    print(\"Evaluating meta-learner...\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    \n",
    "    print(f\"Meta-learner Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Meta-learner Test Precision: {precision:.4f}\")\n",
    "    print(f\"Meta-learner Test Recall: {recall:.4f}\")\n",
    "    print(f\"Meta-learner Test F1 Score: {f1:.4f}\")\n",
    "    print(f\"Meta-learner Test ROC AUC: {auc:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Meta-learner Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"Meta-learner Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Real', 'Fake']))\n",
    "    \n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "# Evaluate the model with comprehensive metrics\n",
    "metrics = evaluate_meta_learner(meta_learner, test_features, test_labels)\n",
    "\n",
    "# Compare with baseline models if available (optional)\n",
    "if 'xception_model' in globals() and 'efficientnet_model' in globals():\n",
    "    print(\"\\nComparing with base models performance:\")\n",
    "    models = ['Meta-Learner']\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Model': models,\n",
    "        'Accuracy': [metrics[0]],\n",
    "        'Precision': [metrics[1]],\n",
    "        'Recall': [metrics[2]],\n",
    "        'F1 Score': [metrics[3]],\n",
    "        'AUC': [metrics[4]]\n",
    "    })\n",
    "    \n",
    "    print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c420b95",
   "metadata": {},
   "source": [
    "# Visualize Model Predictions on Validation Set\n",
    "Let's visualize how our model performs on the validation set to get a better understanding of its strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting validation file paths\n",
    "val_file_paths = val_generator.filepaths\n",
    "\n",
    "print(\"Visualizing sample predictions on validation set...\")\n",
    "visualize_sample_predictions(meta_learner, val_features, val_labels, val_file_paths, num_samples=5)\n",
    "\n",
    "# Optional: You can also see more examples by increasing the number of samples\n",
    "# Uncomment the line below to see 10 examples instead\n",
    "# visualize_sample_predictions(meta_learner, val_features, val_labels, val_file_paths, num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b207c18b",
   "metadata": {},
   "source": [
    "# Visualize Model Predictions on Test Set\n",
    "Let's also visualize how our model performs on the test set to assess its generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe45496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting test file paths\n",
    "test_file_paths = test_generator.filepaths\n",
    "\n",
    "print(\"Visualizing sample predictions on test set...\")\n",
    "visualize_sample_predictions(meta_learner, test_features, test_labels, test_file_paths, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a19eea",
   "metadata": {},
   "source": [
    "# Sample Model Predictions\n",
    "Visualize a few sample predictions from our model to see how well it's performing on specific examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a878bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_predictions(model, features, labels, true_file_paths, num_samples=5):\n",
    "    \"\"\"Visualize sample predictions from the model with original images\"\"\"\n",
    "    import random\n",
    "    import cv2\n",
    "    from tensorflow.keras.preprocessing.image import load_img\n",
    "    \n",
    "    # Generate predictions for all samples\n",
    "    pred_probs = model.predict(features)\n",
    "    predictions = (pred_probs > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Find correct and incorrect predictions\n",
    "    correct_indices = np.where(predictions == labels)[0]\n",
    "    incorrect_indices = np.where(predictions != labels)[0]\n",
    "    \n",
    "    # Try to get an even mix of correct and incorrect predictions if possible\n",
    "    num_correct = min(num_samples // 2 + num_samples % 2, len(correct_indices))\n",
    "    num_incorrect = min(num_samples // 2, len(incorrect_indices))\n",
    "    \n",
    "    # If we don't have enough incorrect predictions, use more correct ones\n",
    "    if num_incorrect < num_samples // 2:\n",
    "        num_correct = min(num_samples - num_incorrect, len(correct_indices))\n",
    "    \n",
    "    # If we don't have enough correct predictions, use more incorrect ones\n",
    "    if num_correct < num_samples // 2 + num_samples % 2:\n",
    "        num_incorrect = min(num_samples - num_correct, len(incorrect_indices))\n",
    "    \n",
    "    # Randomly sample from correct and incorrect predictions\n",
    "    sampled_correct = random.sample(list(correct_indices), num_correct) if num_correct > 0 else []\n",
    "    sampled_incorrect = random.sample(list(incorrect_indices), num_incorrect) if num_incorrect > 0 else []\n",
    "    \n",
    "    # Combine the samples\n",
    "    sampled_indices = sampled_correct + sampled_incorrect\n",
    "    random.shuffle(sampled_indices)  # Shuffle to mix correct and incorrect predictions\n",
    "    \n",
    "    # Limit to the requested number of samples\n",
    "    sampled_indices = sampled_indices[:num_samples]\n",
    "    \n",
    "    # Create a figure to display the results\n",
    "    plt.figure(figsize=(12, 4 * num_samples))\n",
    "    \n",
    "    for i, idx in enumerate(sampled_indices):\n",
    "        # Get the prediction details\n",
    "        true_label = labels[idx]\n",
    "        pred_label = predictions[idx]\n",
    "        prob = pred_probs[idx][0]\n",
    "        \n",
    "        # Get the corresponding file path\n",
    "        file_path = true_file_paths[idx]\n",
    "        \n",
    "        # Load the image\n",
    "        try:\n",
    "            img = load_img(file_path)\n",
    "            plt.subplot(num_samples, 1, i+1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Set title based on prediction correctness\n",
    "            if true_label == pred_label:\n",
    "                result = \"CORRECT\"\n",
    "                color = 'green'\n",
    "            else:\n",
    "                result = \"INCORRECT\"\n",
    "                color = 'red'\n",
    "                \n",
    "            true_text = \"Real\" if true_label == 0 else \"Fake\"\n",
    "            pred_text = \"Real\" if pred_label == 0 else \"Fake\"\n",
    "            \n",
    "            title = f\"{result}: {file_path.split('/')[-2]}\\nTrue: {true_text}, Predicted: {pred_text} (Confidence: {prob:.4f})\"\n",
    "            plt.title(title, color=color, fontsize=12)\n",
    "            \n",
    "        except Exception as e:\n",
    "            plt.subplot(num_samples, 1, i+1)\n",
    "            plt.text(0.5, 0.5, f\"Error loading image: {e}\", ha='center', va='center')\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80396769",
   "metadata": {},
   "source": [
    "# Robustness Testing\n",
    "Test the model's robustness to variations in brightness as mentioned in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62bc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_robustness(meta_learner, selected_indices, test_dir):\n",
    "    \"\"\"Test model robustness with brightness variations as mentioned in the paper\"\"\"\n",
    "    print(\"Testing model robustness to brightness variations...\")\n",
    "    \n",
    "    # Create feature extractors\n",
    "    xception_extractor = create_feature_extractor('xception', IMAGE_SIZE)\n",
    "    efficientnet_extractor = create_feature_extractor('efficientnet', IMAGE_SIZE)\n",
    "    \n",
    "    # Create data generators with brightness variations\n",
    "    brightness_variations = [0.5, 0.75, 1.0, 1.25, 1.5]  # 50%, 75%, 100%, 125%, 150%\n",
    "    results = []\n",
    "    \n",
    "    for brightness in brightness_variations:\n",
    "        print(f\"Testing with brightness factor: {brightness}\")\n",
    "        \n",
    "        # Create a test generator with brightness adjustment\n",
    "        test_brightness_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=xception_preprocess,\n",
    "            brightness_range=[brightness, brightness]\n",
    "        )\n",
    "        \n",
    "        test_brightness_gen = test_brightness_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='binary',\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Extract features for Xception\n",
    "        test_x_features, test_labels = extract_features(xception_extractor, test_brightness_gen, f'Xception Brightness-{brightness}')\n",
    "        \n",
    "        # Reset generator for EfficientNet\n",
    "        test_brightness_gen = test_brightness_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='binary',\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Extract features for EfficientNet\n",
    "        test_e_features, _ = extract_features(efficientnet_extractor, test_brightness_gen, f'EfficientNet Brightness-{brightness}')\n",
    "        \n",
    "        # Stack features\n",
    "        test_stacked = np.concatenate([test_x_features, test_e_features], axis=1)\n",
    "        \n",
    "        # Apply feature selection\n",
    "        # Create feature mask\n",
    "        feature_mask = np.zeros(test_stacked.shape[1], dtype=bool)\n",
    "        feature_mask[selected_indices] = True\n",
    "        \n",
    "        # Select features\n",
    "        test_selected = test_stacked[:, feature_mask]\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = (meta_learner.predict(test_selected) > 0.5).astype(\"int32\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(test_labels, y_pred)\n",
    "        precision = precision_score(test_labels, y_pred)\n",
    "        recall = recall_score(test_labels, y_pred)\n",
    "        f1 = f1_score(test_labels, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'brightness': brightness,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        })\n",
    "        \n",
    "        print(f\"Brightness {brightness} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    # Convert results to DataFrame for easier analysis\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df_results['brightness'], df_results['accuracy'], 'o-', label='Accuracy')\n",
    "    plt.plot(df_results['brightness'], df_results['f1_score'], 's-', label='F1 Score')\n",
    "    plt.plot(df_results['brightness'], df_results['precision'], '^-', label='Precision')\n",
    "    plt.plot(df_results['brightness'], df_results['recall'], 'd-', label='Recall')\n",
    "    plt.xlabel('Brightness Factor')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Robustness to Brightness Variations')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display results as a table\n",
    "    print(\"\\nRobustness Test Results:\")\n",
    "    print(df_results.round(4))\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "# Run robustness test\n",
    "# Comment out the next line if you want to skip this test during initial development\n",
    "robustness_results = test_model_robustness(meta_learner, selected_indices, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d52bcb",
   "metadata": {},
   "source": [
    "# Save and Export Results\n",
    "Save the trained model and export results such as predictions or performance metrics to Google Drive or a downloadable file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79eb4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, evaluate the model to get metrics\n",
    "print(\"Evaluating model on test set to get final metrics...\")\n",
    "# Get predictions\n",
    "test_predictions = (meta_learner.predict(test_features) > 0.5).astype(\"int32\")\n",
    "test_pred_prob = meta_learner.predict(test_features)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "precision = precision_score(test_labels, test_predictions)\n",
    "recall = recall_score(test_labels, test_predictions)\n",
    "f1 = f1_score(test_labels, test_predictions)\n",
    "auc = roc_auc_score(test_labels, test_pred_prob)\n",
    "\n",
    "metrics = [accuracy, precision, recall, f1, auc]\n",
    "print(f\"Final metrics - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "# Save the trained model and feature selection indices\n",
    "# Create a directory for saved models if it doesn't exist\n",
    "os.makedirs('/content/saved_models', exist_ok=True)\n",
    "\n",
    "# Save the meta-learner model\n",
    "meta_learner.save('/content/saved_models/meta_learner_model.h5')\n",
    "\n",
    "# Save the selected feature indices\n",
    "np.save('/content/saved_models/selected_feature_indices.npy', selected_indices)\n",
    "\n",
    "# Export predictions to CSV\n",
    "np.savetxt('/content/saved_models/test_predictions.csv', test_predictions, delimiter=',', fmt='%d')\n",
    "\n",
    "# Save performance metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'],\n",
    "    'Score': metrics\n",
    "})\n",
    "metrics_df.to_csv('/content/saved_models/performance_metrics.csv', index=False)\n",
    "\n",
    "print(\"Model, predictions, and metrics saved successfully to '/content/saved_models' directory\")\n",
    "\n",
    "# For Google Colab: Download files to local machine\n",
    "try:\n",
    "    from google.colab import files\n",
    "    # Compress the saved_models directory\n",
    "    !zip -r /content/saved_models.zip /content/saved_models\n",
    "    # Download the zip file\n",
    "    files.download('/content/saved_models.zip')\n",
    "    print(\"\\nDownload initiated for saved_models.zip\")\n",
    "except ImportError:\n",
    "    print(\"\\nNot running in Google Colab, files saved locally only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce5009",
   "metadata": {},
   "source": [
    "# Inference on New Data\n",
    "Run inference on new images or videos to detect deepfakes using our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_on_new_data(image_path=None, video_path=None, model_path='/content/saved_models/meta_learner_model.h5', indices_path='/content/saved_models/selected_feature_indices.npy'):\n",
    "    \"\"\"Function to run inference on new images or videos\"\"\"\n",
    "    if image_path is None and video_path is None:\n",
    "        print(\"Please provide either an image path or a video path\")\n",
    "        return\n",
    "    \n",
    "    # Load the meta-learner model\n",
    "    try:\n",
    "        from tensorflow.keras.models import load_model\n",
    "        meta_learner = load_model(model_path)\n",
    "        selected_indices = np.load(indices_path)\n",
    "        print(f\"Loaded model from {model_path} and selected features from {indices_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        print(\"Please ensure the model and feature indices files exist\")\n",
    "        return\n",
    "    \n",
    "    # Create feature extractors\n",
    "    xception_extractor = create_feature_extractor('xception', IMAGE_SIZE)\n",
    "    efficientnet_extractor = create_feature_extractor('efficientnet', IMAGE_SIZE)\n",
    "    \n",
    "    if image_path:\n",
    "        process_image(image_path, xception_extractor, efficientnet_extractor, meta_learner, selected_indices)\n",
    "    elif video_path:\n",
    "        process_video(video_path, xception_extractor, efficientnet_extractor, meta_learner, selected_indices)\n",
    "\n",
    "def process_image(image_path, xception_extractor, efficientnet_extractor, meta_learner, selected_indices):\n",
    "    \"\"\"Process a single image for deepfake detection\"\"\"\n",
    "    from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "    import time\n",
    "    \n",
    "    print(f\"Processing image: {image_path}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    img = load_img(image_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = xception_preprocess(img_array)\n",
    "    \n",
    "    # Extract features\n",
    "    xception_features = xception_extractor.predict(img_array, verbose=0)\n",
    "    efficientnet_features = efficientnet_extractor.predict(img_array, verbose=0)\n",
    "    \n",
    "    # Stack features\n",
    "    stacked_features = np.concatenate([xception_features, efficientnet_features], axis=1)\n",
    "    \n",
    "    # Apply feature selection\n",
    "    feature_mask = np.zeros(stacked_features.shape[1], dtype=bool)\n",
    "    feature_mask[selected_indices] = True\n",
    "    selected_features = stacked_features[:, feature_mask]\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction_prob = meta_learner.predict(selected_features, verbose=0)[0][0]\n",
    "    prediction = 1 if prediction_prob > 0.5 else 0\n",
    "    \n",
    "    # Calculate processing time\n",
    "    process_time = time.time() - start_time\n",
    "    \n",
    "    # Display result\n",
    "    label = \"Fake\" if prediction == 1 else \"Real\"\n",
    "    confidence = prediction_prob if prediction == 1 else 1 - prediction_prob\n",
    "    print(f\"Prediction: {label} (confidence: {confidence:.4f})\")\n",
    "    print(f\"Processing time: {process_time:.2f} seconds\")\n",
    "    \n",
    "    # Display the image with prediction\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(load_img(image_path))\n",
    "    plt.title(f\"Prediction: {label} (confidence: {confidence:.4f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return label, confidence\n",
    "\n",
    "def process_video(video_path, xception_extractor, efficientnet_extractor, meta_learner, selected_indices):\n",
    "    \"\"\"Process a video for deepfake detection\"\"\"\n",
    "    import cv2\n",
    "    from tqdm.notebook import tqdm\n",
    "    import time\n",
    "    \n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration = frame_count / fps\n",
    "    \n",
    "    print(f\"Video info - Frames: {frame_count}, FPS: {fps:.2f}, Duration: {duration:.2f}s\")\n",
    "    \n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    frames_to_show = []\n",
    "    \n",
    "    # Process frames at regular intervals (analyze ~20 frames throughout the video)\n",
    "    interval = max(1, frame_count // 20)\n",
    "    frames_to_process = range(0, frame_count, interval)\n",
    "    \n",
    "    for i in tqdm(frames_to_process, desc=\"Processing video frames\"):\n",
    "        # Set the position of the next frame to read\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(f\"Failed to read frame {i}\")\n",
    "            continue\n",
    "        \n",
    "        # Convert frame from BGR to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Save a few frames to display later\n",
    "        if len(frames_to_show) < 4 and i % (interval * 4) == 0:\n",
    "            frames_to_show.append((i, frame_rgb.copy()))\n",
    "        \n",
    "        # Resize frame\n",
    "        frame_resized = cv2.resize(frame_rgb, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        \n",
    "        # Preprocess frame\n",
    "        frame_array = np.expand_dims(frame_resized, axis=0)\n",
    "        frame_array = xception_preprocess(frame_array)\n",
    "        \n",
    "        # Extract features\n",
    "        xception_features = xception_extractor.predict(frame_array, verbose=0)\n",
    "        efficientnet_features = efficientnet_extractor.predict(frame_array, verbose=0)\n",
    "        \n",
    "        # Stack features\n",
    "        stacked_features = np.concatenate([xception_features, efficientnet_features], axis=1)\n",
    "        \n",
    "        # Apply feature selection\n",
    "        feature_mask = np.zeros(stacked_features.shape[1], dtype=bool)\n",
    "        feature_mask[selected_indices] = True\n",
    "        selected_features = stacked_features[:, feature_mask]\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction_prob = meta_learner.predict(selected_features, verbose=0)[0][0]\n",
    "        prediction = 1 if prediction_prob > 0.5 else 0\n",
    "        \n",
    "        # Save results\n",
    "        predictions.append(prediction)\n",
    "        probabilities.append(prediction_prob)\n",
    "    \n",
    "    # Close the video file\n",
    "    cap.release()\n",
    "    \n",
    "    # Calculate final prediction and metrics\n",
    "    final_prediction = 1 if sum(predictions) / len(predictions) > 0.5 else 0\n",
    "    final_probability = sum(probabilities) / len(probabilities)\n",
    "    processing_time = time.time() - start_time\n",
    "    \n",
    "    # Display result\n",
    "    label = \"Fake\" if final_prediction == 1 else \"Real\"\n",
    "    confidence = final_probability if final_prediction == 1 else 1 - final_probability\n",
    "    print(f\"Video prediction: {label} (confidence: {confidence:.4f})\")\n",
    "    print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "    \n",
    "    # Display sample frames\n",
    "    if frames_to_show:\n",
    "        plt.figure(figsize=(16, 4 * len(frames_to_show) // 2))\n",
    "        for idx, (frame_idx, frame) in enumerate(frames_to_show):\n",
    "            plt.subplot(len(frames_to_show) // 2 + len(frames_to_show) % 2, 2, idx + 1)\n",
    "            plt.imshow(frame)\n",
    "            time_point = frame_idx / fps\n",
    "            plt.title(f\"Frame {frame_idx} (Time: {time_point:.2f}s)\")\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot predictions over time\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    time_points = [i / fps for i in frames_to_process[:len(probabilities)]]\n",
    "    plt.plot(time_points, probabilities, 'o-', markersize=4, label='Frame Predictions')\n",
    "    plt.axhline(y=0.5, color='r', linestyle='--', label='Decision Threshold')\n",
    "    plt.axhline(y=final_probability, color='g', linestyle='-', label='Average Prediction')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Probability of Fake')\n",
    "    plt.title(f\"Video Classification: {label} (confidence: {confidence:.4f})\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return label, confidence\n",
    "\n",
    "# Example usage (uncomment to use)\n",
    "# inference_on_new_data(image_path='/content/PreprocessedDatasetV1/test/real/example.jpg')  # For single image\n",
    "# inference_on_new_data(video_path='/content/example_video.mp4')  # For video"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
