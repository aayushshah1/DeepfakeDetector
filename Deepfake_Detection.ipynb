{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f451f63d",
   "metadata": {},
   "source": [
    "# Deepfake Detection using Deep Feature Stacking and Meta-Learning\n",
    "\n",
    "## Implementation of the research paper:\n",
    "- Paper: **Deepfake Detection using Deep Feature Stacking and Meta-Learning**\n",
    "- Authors: Gourab Naskar, Sk Mohiuddin, Samir Malakar, Erik Cuevas, Ram Sarkar\n",
    "\n",
    "This notebook implements a deepfake detection method using:\n",
    "- Xception - Extracts deep features from images\n",
    "- EfficientNet-B7 - Extracts additional feature representations\n",
    "- Feature Selection - Ranking-based selection to reduce redundant features\n",
    "- Meta-Learner (MLP) - Uses selected features to classify Real vs Fake videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61b1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (use -q flag to suppress output)\n",
    "!pip install -q tensorflow keras scikit-learn tqdm matplotlib seaborn pandas numpy\n",
    "!pip install -q opencv-python-headless\n",
    "!pip install -q efficientnet\n",
    "\n",
    "# Check for GPU availability\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU'))}\")\n",
    "\n",
    "# Enable memory growth for GPU to avoid OOM errors\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    for device in physical_devices:\n",
    "        tf.config.experimental.set_memory_growth(device, True)\n",
    "    print(f\"Memory growth enabled on {len(physical_devices)} GPU(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2833537",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import all the libraries needed for the project, including TensorFlow, NumPy, Pandas, and Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da478c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input as xception_preprocess\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.applications import EfficientNetV2L, preprocess_input as efficientnetv2_preprocess\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import math\n",
    "\n",
    "# For feature selection and meta-learner\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, f_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060507b5",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Load the dataset from a Google Drive link or a public URL, ensuring compatibility with Colab's file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract dataset\n",
    "!wget https://deep-fake-dataset.s3.eu-north-1.amazonaws.com/PreprocessedDatasetV1.zip -O dataset.zip\n",
    "!unzip -q dataset.zip -d /content\n",
    "\n",
    "# Define dataset paths\n",
    "train_dir = '/content/PreprocessedDatasetV1/train'\n",
    "test_dir = '/content/PreprocessedDatasetV1/test'\n",
    "val_dir = '/content/PreprocessedDatasetV1/validation'\n",
    "\n",
    "# Check if directories exist\n",
    "!ls -la /content/PreprocessedDatasetV1\n",
    "print(f\"Train directory exists: {os.path.exists(train_dir)}\")\n",
    "print(f\"Test directory exists: {os.path.exists(test_dir)}\")\n",
    "print(f\"Validation directory exists: {os.path.exists(val_dir)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4975e12",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "Perform data preprocessing steps such as resizing images, normalizing pixel values, and splitting the dataset into training, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8411a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "IMAGE_SIZE = 300  # Updated for better performance with EfficientNetV2L\n",
    "BATCH_SIZE = 32   # Adjust based on your GPU memory\n",
    "EPOCHS = 20       # Can be reduced with early stopping\n",
    "FEATURE_PERCENTAGE = 30  # Top k% features to keep (as per paper)\n",
    "\n",
    "# Data generators with proper preprocessing for Xception and EfficientNetV2L\n",
    "# Training data with augmentation\n",
    "train_datagen_xception = ImageDataGenerator(\n",
    "    preprocessing_function=xception_preprocess,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# EfficientNetV2L uses a different preprocessing function\n",
    "train_datagen_efficientnet = ImageDataGenerator(\n",
    "    preprocessing_function=efficientnetv2_preprocess,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Validation and test data only need preprocessing, not augmentation\n",
    "val_datagen_xception = ImageDataGenerator(preprocessing_function=xception_preprocess)\n",
    "test_datagen_xception = ImageDataGenerator(preprocessing_function=xception_preprocess)\n",
    "\n",
    "val_datagen_efficientnet = ImageDataGenerator(preprocessing_function=efficientnetv2_preprocess)\n",
    "test_datagen_efficientnet = ImageDataGenerator(preprocessing_function=efficientnetv2_preprocess)\n",
    "\n",
    "# Create generators for Xception\n",
    "train_generator_xception = train_datagen_xception.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator_xception = val_datagen_xception.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator_xception = test_datagen_xception.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Create generators for EfficientNetV2L\n",
    "train_generator_efficientnet = train_datagen_efficientnet.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator_efficientnet = val_datagen_efficientnet.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator_efficientnet = test_datagen_efficientnet.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Check dataset sizes\n",
    "print(f\"Training samples: {train_generator_xception.samples}\")\n",
    "print(f\"Validation samples: {val_generator_xception.samples}\")\n",
    "print(f\"Testing samples: {test_generator_xception.samples}\")\n",
    "print(f\"Class indices: {train_generator_xception.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d36091",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "Define the deep learning model architecture using TensorFlow or PyTorch, ensuring modularity and clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1230c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, img_size):\n",
    "    \"\"\"Create and compile the CNN model\"\"\"\n",
    "    if model_name == 'xception':\n",
    "        # Create the Xception model directly with the right input shape\n",
    "        base_model = Xception(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(img_size, img_size, 3)\n",
    "        )\n",
    "        \n",
    "    elif model_name == 'efficientnetv2':\n",
    "        # Create EfficientNetV2L model with the right input shape\n",
    "        base_model = EfficientNetV2L(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(img_size, img_size, 3)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not supported\")\n",
    "    \n",
    "    # Add custom classification head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Freeze the base model layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model, base_model\n",
    "\n",
    "# Define CosineAnnealingWarmRestarts learning rate scheduler (equivalent to PyTorch version)\n",
    "class CosineAnnealingWarmRestarts(Callback):\n",
    "    def __init__(self, T_0=10, T_mult=2, eta_min=1e-6, eta_max=1e-3, verbose=0):\n",
    "        super(CosineAnnealingWarmRestarts, self).__init__()\n",
    "        self.T_0 = T_0  # Initial cycle length\n",
    "        self.T_mult = T_mult  # Cycle length multiplication factor\n",
    "        self.eta_min = eta_min  # Minimum learning rate\n",
    "        self.eta_max = eta_max  # Maximum learning rate\n",
    "        self.verbose = verbose\n",
    "        self.current_restart = 0\n",
    "        self.T_cur = 0\n",
    "        self.cycle_length = T_0\n",
    "        self.history = {'lr': []}\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        logs = logs or {}\n",
    "        K = tf.keras.backend\n",
    "        self.model.optimizer.lr = self.eta_max\n",
    "        K.set_value(self.model.optimizer.lr, self.eta_max)\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        K = tf.keras.backend\n",
    "        if epoch == 0:\n",
    "            self.T_cur = 0\n",
    "        \n",
    "        # Calculate new learning rate\n",
    "        lr = self.eta_min + 0.5 * (self.eta_max - self.eta_min) * (1 + math.cos(math.pi * self.T_cur / self.cycle_length))\n",
    "        K.set_value(self.model.optimizer.lr, lr)\n",
    "        \n",
    "        if self.verbose > 0:\n",
    "            print(f'\\nEpoch {epoch+1}: CosineAnnealingWarmRestarts setting learning rate to {lr}.')\n",
    "        \n",
    "        self.history['lr'].append(lr)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.T_cur += 1\n",
    "        \n",
    "        # If we've reached the end of a cycle, reset T_cur and increase cycle length\n",
    "        if self.T_cur >= self.cycle_length:\n",
    "            self.current_restart += 1\n",
    "            self.T_cur = 0\n",
    "            self.cycle_length = self.T_0 * (self.T_mult ** self.current_restart)\n",
    "            if self.verbose > 0:\n",
    "                print(f'\\nRestart {self.current_restart}: New cycle length is {self.cycle_length}')\n",
    "\n",
    "# LR Plotter Callback\n",
    "class LRPlotter(Callback):\n",
    "    def __init__(self, cosine_scheduler):\n",
    "        super(LRPlotter, self).__init__()\n",
    "        self.cosine_scheduler = cosine_scheduler\n",
    "    \n",
    "    def on_train_end(self, logs=None):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.cosine_scheduler.history['lr'])\n",
    "        plt.title('Learning Rate Schedule')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Learning Rate')\n",
    "        plt.yscale('log')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "# Create Xception and EfficientNetV2L models\n",
    "print(\"Creating Xception model...\")\n",
    "xception_model, xception_base = create_model('xception', IMAGE_SIZE)\n",
    "\n",
    "print(\"Creating EfficientNetV2L model...\")\n",
    "efficientnet_model, efficientnet_base = create_model('efficientnetv2', IMAGE_SIZE)\n",
    "\n",
    "# Print model summaries\n",
    "print(\"\\nXception Model Summary:\")\n",
    "xception_model.summary()\n",
    "\n",
    "print(\"\\nEfficientNetV2L Model Summary:\")\n",
    "efficientnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e680f338",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "Train the model on the preprocessed dataset, including callbacks for early stopping and saving the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647483f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_fine_tuning(model, base_model, train_gen, valid_gen, model_name, epochs=EPOCHS):\n",
    "    \"\"\"Train model with two-phase fine tuning strategy using cosine annealing\"\"\"\n",
    "    # Define callbacks\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        f'{model_name}_best_model.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Create cosine annealing scheduler with warm restarts\n",
    "    cosine_scheduler = CosineAnnealingWarmRestarts(\n",
    "        T_0=10,  # Initial cycle length\n",
    "        T_mult=2,  # Cycle length factor\n",
    "        eta_min=1e-6,  # Min learning rate\n",
    "        eta_max=1e-3,  # Max learning rate\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Create LR plotter to track and visualize learning rate\n",
    "    lr_plotter = LRPlotter(cosine_scheduler)\n",
    "    \n",
    "    callbacks = [checkpoint, early_stop, cosine_scheduler, lr_plotter]\n",
    "    \n",
    "    # Phase 1: Initial training with frozen base model\n",
    "    print(f\"Training {model_name} - Phase 1: Training only top layers\")\n",
    "    history1 = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=valid_gen,\n",
    "        epochs=epochs // 2,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # Phase 2: Unfreeze some layers for fine-tuning\n",
    "    if model_name == 'xception':\n",
    "        for layer in base_model.layers[-30:]:  # Unfreeze last 30 layers\n",
    "            layer.trainable = True\n",
    "    else:  # efficientnetv2\n",
    "        # Unfreeze the last 30% of layers for EfficientNetV2L\n",
    "        unfreeze_layers = int(len(base_model.layers) * 0.3)\n",
    "        for layer in base_model.layers[-unfreeze_layers:]:\n",
    "            layer.trainable = True\n",
    "    \n",
    "    # Recompile with lower learning rate range\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),  # Starting LR for fine-tuning\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Create new cosine annealing scheduler with lower learning rate ranges for fine-tuning\n",
    "    cosine_scheduler_ft = CosineAnnealingWarmRestarts(\n",
    "        T_0=5,  # Shorter initial cycle for fine-tuning\n",
    "        T_mult=2,  # Same multiplication factor\n",
    "        eta_min=1e-7,  # Lower min learning rate\n",
    "        eta_max=1e-4,  # Lower max learning rate\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Create new LR plotter for fine-tuning phase\n",
    "    lr_plotter_ft = LRPlotter(cosine_scheduler_ft)\n",
    "    \n",
    "    # Update callbacks for fine-tuning phase\n",
    "    callbacks = [checkpoint, early_stop, cosine_scheduler_ft, lr_plotter_ft]\n",
    "    \n",
    "    print(f\"Training {model_name} - Phase 2: Fine-tuning\")\n",
    "    history2 = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=valid_gen,\n",
    "        epochs=epochs // 2,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "    \n",
    "    # Combine histories\n",
    "    combined_history = {}\n",
    "    for key in history1.history.keys():\n",
    "        if key != 'lr':  # Skip learning rate as it was handled differently\n",
    "            combined_history[key] = history1.history[key] + history2.history[key]\n",
    "    \n",
    "    # Combine learning rate histories\n",
    "    combined_history['lr'] = cosine_scheduler.history['lr'] + cosine_scheduler_ft.history['lr']\n",
    "    \n",
    "    return model, combined_history\n",
    "\n",
    "# Function to plot learning rate schedule\n",
    "def plot_lr_schedule(history, model_name):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(history['lr'])\n",
    "    plt.title(f'{model_name} Learning Rate Schedule')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning Rate')\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Train both models with fine-tuning\n",
    "print(\"\\n==== Training Xception Model ====\")\n",
    "xception_model, xception_history = train_model_with_fine_tuning(\n",
    "    xception_model, xception_base, train_generator_xception, val_generator_xception, 'xception'\n",
    ")\n",
    "\n",
    "# Plot learning rate schedule for Xception model\n",
    "plot_lr_schedule(xception_history, 'Xception')\n",
    "\n",
    "# Clear memory before training next model\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"\\n==== Training EfficientNetV2L Model ====\")\n",
    "efficientnet_model, efficientnet_history = train_model_with_fine_tuning(\n",
    "    efficientnet_model, efficientnet_base, train_generator_efficientnet, val_generator_efficientnet, 'efficientnetv2'\n",
    ")\n",
    "\n",
    "# Plot learning rate schedule for EfficientNetV2L model\n",
    "plot_lr_schedule(efficientnet_history, 'EfficientNetV2L')\n",
    "\n",
    "# Plot training history for both models\n",
    "def plot_training_history(history, model_name):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'{model_name} Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot training histories\n",
    "plot_training_history(xception_history, 'Xception')\n",
    "plot_training_history(efficientnet_history, 'EfficientNetV2L')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351118ca",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "Create feature extractors from the trained models and extract deep features from the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c71d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature_extractor(model_name, img_size):\n",
    "    \"\"\"Create a feature extractor model\"\"\"\n",
    "    if model_name == 'xception':\n",
    "        base_model = Xception(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(img_size, img_size, 3),\n",
    "            pooling='avg'\n",
    "        )\n",
    "        return base_model\n",
    "        \n",
    "    elif model_name == 'efficientnetv2':\n",
    "        base_model = EfficientNetV2L(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(img_size, img_size, 3),\n",
    "            pooling='avg'\n",
    "        )\n",
    "        return base_model\n",
    "    else:\n",
    "        raise ValueError(f\"Model {model_name} not supported\")\n",
    "\n",
    "def extract_features(feature_extractor, data_generator, name):\n",
    "    \"\"\"Extract features from a dataset using the given extractor\"\"\"\n",
    "    print(f\"Extracting features using {name}...\")\n",
    "    features = []\n",
    "    labels = []\n",
    "    batch_count = 0\n",
    "    total_batches = len(data_generator)\n",
    "    \n",
    "    for batch_x, batch_y in tqdm(data_generator, total=total_batches):\n",
    "        batch_features = feature_extractor.predict(batch_x, verbose=0)\n",
    "        features.append(batch_features)\n",
    "        labels.append(batch_y)\n",
    "        batch_count += 1\n",
    "        \n",
    "        # Stop when we've gone through the entire dataset\n",
    "        if batch_count >= total_batches:\n",
    "            break\n",
    "    \n",
    "    # Concatenate all batches\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    print(f\"{name} features shape: {features.shape}\")\n",
    "    print(f\"{name} labels shape: {labels.shape}\")\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "# Create feature extractors\n",
    "print(\"Creating feature extractors...\")\n",
    "xception_extractor = create_feature_extractor('xception', IMAGE_SIZE)\n",
    "efficientnetv2_extractor = create_feature_extractor('efficientnetv2', IMAGE_SIZE)\n",
    "\n",
    "# Reset generators for feature extraction (shuffle=False to maintain order)\n",
    "train_gen_features_xception = ImageDataGenerator(preprocessing_function=xception_preprocess).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Important: keep order of samples\n",
    ")\n",
    "\n",
    "val_gen_features_xception = ImageDataGenerator(preprocessing_function=xception_preprocess).flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen_features_xception = ImageDataGenerator(preprocessing_function=xception_preprocess).flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Extract features for train set with Xception\n",
    "train_xception_features, train_labels = extract_features(xception_extractor, train_gen_features_xception, 'Train Xception')\n",
    "\n",
    "# Create generators for EfficientNetV2L feature extraction\n",
    "train_gen_features_efficientnet = ImageDataGenerator(preprocessing_function=efficientnetv2_preprocess).flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "val_gen_features_efficientnet = ImageDataGenerator(preprocessing_function=efficientnetv2_preprocess).flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen_features_efficientnet = ImageDataGenerator(preprocessing_function=efficientnetv2_preprocess).flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Extract features for train set with EfficientNetV2L\n",
    "train_efficientnet_features, _ = extract_features(efficientnetv2_extractor, train_gen_features_efficientnet, 'Train EfficientNetV2L')\n",
    "\n",
    "# Extract features for validation set with Xception\n",
    "val_xception_features, val_labels = extract_features(xception_extractor, val_gen_features_xception, 'Val Xception')\n",
    "\n",
    "# Extract features for validation set with EfficientNetV2L\n",
    "val_efficientnet_features, _ = extract_features(efficientnetv2_extractor, val_gen_features_efficientnet, 'Val EfficientNetV2L')\n",
    "\n",
    "# Extract features for test set with Xception\n",
    "test_xception_features, test_labels = extract_features(xception_extractor, test_gen_features_xception, 'Test Xception')\n",
    "\n",
    "# Extract features for test set with EfficientNetV2L\n",
    "test_efficientnet_features, _ = extract_features(efficientnetv2_extractor, test_gen_features_efficientnet, 'Test EfficientNetV2L')\n",
    "\n",
    "# Stack features\n",
    "train_features = np.concatenate([train_xception_features, train_efficientnet_features], axis=1)\n",
    "val_features = np.concatenate([val_xception_features, val_efficientnet_features], axis=1)\n",
    "test_features = np.concatenate([test_xception_features, test_efficientnet_features], axis=1)\n",
    "\n",
    "print(f\"Stacked feature shapes - Train: {train_features.shape}, Val: {val_features.shape}, Test: {test_features.shape}\")\n",
    "\n",
    "# Clear memory\n",
    "del xception_extractor, efficientnetv2_extractor\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f6000",
   "metadata": {},
   "source": [
    "# Advanced Feature Selection\n",
    "Implement a more sophisticated feature selection pipeline with correlation filtering and Recursive Feature Elimination with Cross-Validation (RFECV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667409be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_feature_selection(train_features, train_labels, val_features, test_features):\n",
    "    \"\"\"Advanced feature selection using correlation filtering and RFECV\"\"\"\n",
    "    print(\"Starting advanced feature selection pipeline...\")\n",
    "    \n",
    "    # Step 1: Remove highly correlated features\n",
    "    print(\"\\n1. Removing highly correlated features...\")\n",
    "    print(f\"Original number of features: {train_features.shape[1]}\")\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    print(\"Computing feature correlation matrix...\")\n",
    "    corr_matrix = np.corrcoef(train_features, rowvar=False)\n",
    "    \n",
    "    # Identify highly correlated features (Pearson correlation > 0.9)\n",
    "    threshold = 0.9\n",
    "    feature_indices_to_keep = []\n",
    "    \n",
    "    # Find features to keep (not highly correlated with already selected features)\n",
    "    for i in range(corr_matrix.shape[0]):\n",
    "        # If this is the first feature or it's not highly correlated with any already selected feature\n",
    "        if i == 0 or not any(abs(corr_matrix[i, j]) > threshold for j in feature_indices_to_keep):\n",
    "            feature_indices_to_keep.append(i)\n",
    "    \n",
    "    print(f\"After correlation filtering: Keeping {len(feature_indices_to_keep)} out of {train_features.shape[1]} features\")\n",
    "    \n",
    "    # Apply correlation-based feature filtering\n",
    "    train_filtered = train_features[:, feature_indices_to_keep]\n",
    "    val_filtered = val_features[:, feature_indices_to_keep]\n",
    "    test_filtered = test_features[:, feature_indices_to_keep]\n",
    "    \n",
    "    # Visualize correlation matrix after filtering\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    filtered_corr = np.corrcoef(train_filtered, rowvar=False)\n",
    "    mask = np.triu(np.ones_like(filtered_corr, dtype=bool))\n",
    "    sns.heatmap(filtered_corr, mask=mask, cmap='coolwarm', center=0, square=True, linewidths=.5)\n",
    "    plt.title('Correlation Matrix After Filtering')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Step 2: Apply Recursive Feature Elimination with Cross-Validation (RFECV)\n",
    "    print(\"\\n2. Applying RFECV to find optimal feature subset...\")\n",
    "    \n",
    "    # Define cross-validation strategy\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Create and train Random Forest for RFECV\n",
    "    print(\"Training RF-based RFECV...\")\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "    rfecv_rf = RFECV(estimator=rf_model, step=0.05, cv=cv, scoring='f1', n_jobs=-1, verbose=1)\n",
    "    rfecv_rf.fit(train_filtered, train_labels)\n",
    "    \n",
    "    # Create and train XGBoost for RFECV\n",
    "    print(\"\\nTraining XGBoost-based RFECV...\")\n",
    "    xgb_model = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='logloss', n_jobs=-1)\n",
    "    rfecv_xgb = RFECV(estimator=xgb_model, step=0.05, cv=cv, scoring='f1', n_jobs=-1, verbose=1)\n",
    "    rfecv_xgb.fit(train_filtered, train_labels)\n",
    "    \n",
    "    # Visualize RFECV results\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(rfecv_rf.grid_scores_) + 1), rfecv_rf.grid_scores_, 'o-')\n",
    "    plt.axvline(x=rfecv_rf.n_features_, color='r', linestyle='--')\n",
    "    plt.title(f'RF-RFECV - Optimal features: {rfecv_rf.n_features_}')\n",
    "    plt.xlabel('Number of features')\n",
    "    plt.ylabel('F1 score (CV)')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, len(rfecv_xgb.grid_scores_) + 1), rfecv_xgb.grid_scores_, 'o-')\n",
    "    plt.axvline(x=rfecv_xgb.n_features_, color='r', linestyle='--')\n",
    "    plt.title(f'XGB-RFECV - Optimal features: {rfecv_xgb.n_features_}')\n",
    "    plt.xlabel('Number of features')\n",
    "    plt.ylabel('F1 score (CV)')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Step 3: Combine RFECV results from both models\n",
    "    print(\"\\n3. Combining feature selection results from RF and XGBoost RFECV...\")\n",
    "    \n",
    "    # Convert support masks to arrays of 0s and 1s\n",
    "    rf_support = rfecv_rf.support_.astype(int)\n",
    "    xgb_support = rfecv_xgb.support_.astype(int)\n",
    "    \n",
    "    # Count models that selected each feature (0, 1, or 2)\n",
    "    combined_support = rf_support + xgb_support\n",
    "    \n",
    "    # Select features that are chosen by at least one model\n",
    "    final_mask = combined_support >= 1\n",
    "    final_filtered_indices = np.where(final_mask)[0]\n",
    "    \n",
    "    # Map back to original feature indices\n",
    "    final_indices = [feature_indices_to_keep[i] for i in final_filtered_indices]\n",
    "    \n",
    "    print(f\"Final selected features: {len(final_indices)} out of {train_features.shape[1]} original features\")\n",
    "    print(f\"RF selected: {rfecv_rf.n_features_}, XGBoost selected: {rfecv_xgb.n_features_}, Combined: {len(final_indices)}\")\n",
    "    \n",
    "    # Apply final feature selection to datasets\n",
    "    train_final = train_features[:, final_indices]\n",
    "    val_final = val_features[:, final_indices]\n",
    "    test_final = test_features[:, final_indices]\n",
    "    \n",
    "    # Get feature importances from the final models\n",
    "    rf_importances = rfecv_rf.estimator_.feature_importances_\n",
    "    xgb_importances = rfecv_xgb.estimator_.feature_importances_\n",
    "    \n",
    "    # Normalize importances\n",
    "    rf_importances_norm = rf_importances / np.max(rf_importances)\n",
    "    xgb_importances_norm = xgb_importances / np.max(xgb_importances)\n",
    "    \n",
    "    # Combine importances for selected features\n",
    "    combined_importances = np.zeros(len(final_filtered_indices))\n",
    "    for i, idx in enumerate(final_filtered_indices):\n",
    "        combined_importances[i] = (rf_importances_norm[idx] + xgb_importances_norm[idx]) / 2\n",
    "    \n",
    "    # Visualize top 20 feature importances\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_k = min(20, len(combined_importances))\n",
    "    top_indices = np.argsort(combined_importances)[-top_k:][::-1]\n",
    "    top_importances = combined_importances[top_indices]\n",
    "    \n",
    "    plt.barh(range(top_k), top_importances, color='skyblue')\n",
    "    plt.yticks(range(top_k), [f'Feature {final_indices[idx]}' for idx in top_indices])\n",
    "    plt.title(f'Top {top_k} Feature Importance (Combined RF & XGBoost)')\n",
    "    plt.xlabel('Normalized Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return train_final, val_final, test_final, final_indices\n",
    "\n",
    "# Apply advanced feature selection\n",
    "print(\"Starting advanced feature selection pipeline...\")\n",
    "train_features, val_features, test_features, selected_indices = advanced_feature_selection(\n",
    "    train_features, train_labels, val_features, test_features\n",
    ")\n",
    "\n",
    "print(f\"Final dataset shapes after feature selection:\")\n",
    "print(f\"Train: {train_features.shape}\")\n",
    "print(f\"Validation: {val_features.shape}\")\n",
    "print(f\"Test: {test_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd08dafb",
   "metadata": {},
   "source": [
    "# Enhanced Meta-Learner\n",
    "Implement an ensemble meta-learner with multiple models and weighted voting based on validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd767011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ensemble_meta_learner(train_features, train_labels, val_features, val_labels):\n",
    "    \"\"\"Create an ensemble meta-learner with weighted voting based on validation performance\"\"\"\n",
    "    print(\"Creating ensemble meta-learner with SVM, XGBoost, and MLP...\")\n",
    "    \n",
    "    # Scale features (important for SVM and MLP)\n",
    "    print(\"Scaling features...\")\n",
    "    scaler = StandardScaler()\n",
    "    train_features_scaled = scaler.fit_transform(train_features)\n",
    "    val_features_scaled = scaler.transform(val_features)\n",
    "    \n",
    "    # 1. Train SVM model\n",
    "    print(\"\\n1. Training SVM model...\")\n",
    "    svm_base = SVC(C=1.0, kernel='rbf', probability=True, random_state=42)\n",
    "    svm = CalibratedClassifierCV(svm_base, cv=5, method='isotonic')\n",
    "    svm.fit(train_features_scaled, train_labels)\n",
    "    \n",
    "    # Evaluate SVM on validation set\n",
    "    svm_val_preds = svm.predict(val_features_scaled)\n",
    "    svm_val_probs = svm.predict_proba(val_features_scaled)[:, 1]\n",
    "    svm_accuracy = accuracy_score(val_labels, svm_val_preds)\n",
    "    svm_f1 = f1_score(val_labels, svm_val_preds)\n",
    "    print(f\"SVM Validation - Accuracy: {svm_accuracy:.4f}, F1: {svm_f1:.4f}\")\n",
    "    \n",
    "    # 2. Train XGBoost model\n",
    "    print(\"\\n2. Training XGBoost model...\")\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='binary:logistic',\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    xgb.fit(train_features, train_labels)\n",
    "    \n",
    "    # Apply calibration to XGBoost probabilities\n",
    "    print(\"Calibrating XGBoost probabilities...\")\n",
    "    xgb_calibrated = CalibratedClassifierCV(xgb, cv='prefit', method='isotonic')\n",
    "    xgb_calibrated.fit(val_features, val_labels)\n",
    "    \n",
    "    # Evaluate XGBoost on validation set\n",
    "    xgb_val_preds = xgb_calibrated.predict(val_features)\n",
    "    xgb_val_probs = xgb_calibrated.predict_proba(val_features)[:, 1]\n",
    "    xgb_accuracy = accuracy_score(val_labels, xgb_val_preds)\n",
    "    xgb_f1 = f1_score(val_labels, xgb_val_preds)\n",
    "    print(f\"XGBoost Validation - Accuracy: {xgb_accuracy:.4f}, F1: {xgb_f1:.4f}\")\n",
    "    \n",
    "    # 3. Train MLP model (Keras)\n",
    "    print(\"\\n3. Training MLP model...\")\n",
    "    mlp = Sequential([\n",
    "        Dense(256, activation='relu', input_shape=(train_features.shape[1],)),\n",
    "        Dropout(0.5),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Compile the MLP model\n",
    "    mlp.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Define callbacks for early stopping and learning rate reduction\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_accuracy',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-6,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train the MLP model\n",
    "    history = mlp.fit(\n",
    "        train_features_scaled, train_labels,\n",
    "        validation_data=(val_features_scaled, val_labels),\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate MLP on validation set\n",
    "    mlp_val_probs = mlp.predict(val_features_scaled).flatten()\n",
    "    mlp_val_preds = (mlp_val_probs > 0.5).astype(int)\n",
    "    mlp_accuracy = accuracy_score(val_labels, mlp_val_preds)\n",
    "    mlp_f1 = f1_score(val_labels, mlp_val_preds)\n",
    "    print(f\"MLP Validation - Accuracy: {mlp_accuracy:.4f}, F1: {mlp_f1:.4f}\")\n",
    "    \n",
    "    # Assign weights based on F1 scores\n",
    "    print(\"\\n4. Calculating ensemble voting weights based on performance...\")\n",
    "    total_f1 = svm_f1 + xgb_f1 + mlp_f1\n",
    "    svm_weight = svm_f1 / total_f1\n",
    "    xgb_weight = xgb_f1 / total_f1\n",
    "    mlp_weight = mlp_f1 / total_f1\n",
    "    \n",
    "    weights = {\n",
    "        'svm': svm_weight,\n",
    "        'xgb': xgb_weight,\n",
    "        'mlp': mlp_weight\n",
    "    }\n",
    "    \n",
    "    print(f\"Ensemble weights - SVM: {svm_weight:.3f}, XGBoost: {xgb_weight:.3f}, MLP: {mlp_weight:.3f}\")\n",
    "    \n",
    "    # Implement weighted voting function\n",
    "    def ensemble_predict(features, proba=False):\n",
    "        # Scale features for SVM and MLP\n",
    "        features_scaled = scaler.transform(features)\n",
    "        \n",
    "        # Get probabilities from each model\n",
    "        svm_probs = svm.predict_proba(features_scaled)[:, 1]\n",
    "        xgb_probs = xgb_calibrated.predict_proba(features)[:, 1]\n",
    "        mlp_probs = mlp.predict(features_scaled).flatten()\n",
    "        \n",
    "        # Apply weighted average of probabilities\n",
    "        weighted_probs = (\n",
    "            svm_weight * svm_probs +\n",
    "            xgb_weight * xgb_probs +\n",
    "            mlp_weight * mlp_probs\n",
    "        )\n",
    "        \n",
    "        if proba:\n",
    "            return weighted_probs\n",
    "        else:\n",
    "            # Convert to class predictions (0 or 1)\n",
    "            return (weighted_probs > 0.5).astype(int)\n",
    "    \n",
    "    # Test the ensemble on validation set\n",
    "    ensemble_val_preds = ensemble_predict(val_features)\n",
    "    ensemble_val_probs = ensemble_predict(val_features, proba=True)\n",
    "    ensemble_accuracy = accuracy_score(val_labels, ensemble_val_preds)\n",
    "    ensemble_f1 = f1_score(val_labels, ensemble_val_preds)\n",
    "    \n",
    "    print(f\"\\nEnsemble Validation - Accuracy: {ensemble_accuracy:.4f}, F1: {ensemble_f1:.4f}\")\n",
    "    \n",
    "    # Compare model performances\n",
    "    models = ['SVM', 'XGBoost', 'MLP', 'Ensemble']\n",
    "    accuracies = [svm_accuracy, xgb_accuracy, mlp_accuracy, ensemble_accuracy]\n",
    "    f1_scores = [svm_f1, xgb_f1, mlp_f1, ensemble_f1]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(models, accuracies, color=['#ff9999', '#66b3ff', '#99ff99', '#ffcc99'])\n",
    "    plt.title('Validation Accuracy Comparison')\n",
    "    plt.ylim(min(accuracies) - 0.05, max(accuracies) + 0.05)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    # Add values on top of bars\n",
    "    for i, acc in enumerate(accuracies):\n",
    "        plt.text(i, acc + 0.01, f'{acc:.4f}', ha='center')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(models, f1_scores, color=['#ff9999', '#66b3ff', '#99ff99', '#ffcc99'])\n",
    "    plt.title('Validation F1 Score Comparison')\n",
    "    plt.ylim(min(f1_scores) - 0.05, max(f1_scores) + 0.05)\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    # Add values on top of bars\n",
    "    for i, f1 in enumerate(f1_scores):\n",
    "        plt.text(i, f1 + 0.01, f'{f1:.4f}', ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot calibration curves\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Function to calculate calibration curve\n",
    "    def calculate_calibration(y_true, y_proba, n_bins=10):\n",
    "        bin_edges = np.linspace(0, 1, n_bins + 1)\n",
    "        bin_indices = np.digitize(y_proba, bin_edges) - 1\n",
    "        bin_indices = np.clip(bin_indices, 0, n_bins - 1)  # Ensure within bounds\n",
    "        \n",
    "        bin_sums = np.bincount(bin_indices, minlength=n_bins)\n",
    "        bin_true = np.bincount(bin_indices, weights=y_true, minlength=n_bins)\n",
    "        bin_probs = np.zeros(n_bins)\n",
    "        \n",
    "        for i in range(n_bins):\n",
    "            if bin_sums[i] > 0:\n",
    "                bin_probs[i] = bin_true[i] / bin_sums[i]\n",
    "            else:\n",
    "                bin_probs[i] = np.nan\n",
    "        \n",
    "        bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "        return bin_centers, bin_probs\n",
    "    \n",
    "    # Calculate and plot calibration curves for each model\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Perfectly calibrated')\n",
    "    \n",
    "    # SVM calibration curve\n",
    "    svm_bin_centers, svm_bin_probs = calculate_calibration(val_labels, svm_val_probs)\n",
    "    plt.plot(svm_bin_centers, svm_bin_probs, 'o-', label=f'SVM (w={svm_weight:.2f})', markersize=8)\n",
    "    \n",
    "    # XGBoost calibration curve\n",
    "    xgb_bin_centers, xgb_bin_probs = calculate_calibration(val_labels, xgb_val_probs)\n",
    "    plt.plot(xgb_bin_centers, xgb_bin_probs, 's-', label=f'XGBoost (w={xgb_weight:.2f})', markersize=8)\n",
    "    \n",
    "    # MLP calibration curve\n",
    "    mlp_bin_centers, mlp_bin_probs = calculate_calibration(val_labels, mlp_val_probs)\n",
    "    plt.plot(mlp_bin_centers, mlp_bin_probs, '^-', label=f'MLP (w={mlp_weight:.2f})', markersize=8)\n",
    "    \n",
    "    # Ensemble calibration curve\n",
    "    ens_bin_centers, ens_bin_probs = calculate_calibration(val_labels, ensemble_val_probs)\n",
    "    plt.plot(ens_bin_centers, ens_bin_probs, 'D-', label='Ensemble', markersize=8, linewidth=2)\n",
    "    \n",
    "    plt.xlabel('Mean predicted probability')\n",
    "    plt.ylabel('Fraction of positives')\n",
    "    plt.title('Calibration Curves (Reliability Diagram)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot MLP training history\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title('MLP Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title('MLP Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Return ensemble components and prediction function\n",
    "    ensemble = {\n",
    "        'svm': svm,\n",
    "        'xgb': xgb_calibrated,\n",
    "        'mlp': mlp,\n",
    "        'scaler': scaler,\n",
    "        'weights': weights,\n",
    "        'predict': ensemble_predict,\n",
    "        'history': history.history\n",
    "    }\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "# Create and train the ensemble meta-learner\n",
    "print(\"Training ensemble meta-learner...\")\n",
    "ensemble_meta_learner = create_ensemble_meta_learner(train_features, train_labels, val_features, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad0836",
   "metadata": {},
   "source": [
    "# Evaluate the Enhanced Ensemble Meta-Learner\n",
    "Evaluate the ensemble meta-learner's performance on the test dataset, comparing with individual model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05efa310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ensemble(ensemble, X_test, y_test):\n",
    "    \"\"\"Evaluate the ensemble meta-learner on test data\"\"\"\n",
    "    print(\"Evaluating ensemble meta-learner on test set...\")\n",
    "    \n",
    "    # Scale features for models that need scaling\n",
    "    X_test_scaled = ensemble['scaler'].transform(X_test)\n",
    "    \n",
    "    # Get predictions from individual models\n",
    "    svm_probs = ensemble['svm'].predict_proba(X_test_scaled)[:, 1]\n",
    "    svm_preds = (svm_probs > 0.5).astype(int)\n",
    "    \n",
    "    xgb_probs = ensemble['xgb'].predict_proba(X_test)[:, 1]\n",
    "    xgb_preds = (xgb_probs > 0.5).astype(int)\n",
    "    \n",
    "    mlp_probs = ensemble['mlp'].predict(X_test_scaled).flatten()\n",
    "    mlp_preds = (mlp_probs > 0.5).astype(int)\n",
    "    \n",
    "    # Get ensemble predictions\n",
    "    ensemble_probs = ensemble['predict'](X_test, proba=True)\n",
    "    ensemble_preds = (ensemble_probs > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate metrics for all models\n",
    "    models = ['SVM', 'XGBoost', 'MLP', 'Ensemble']\n",
    "    predictions = [svm_preds, xgb_preds, mlp_preds, ensemble_preds]\n",
    "    probabilities = [svm_probs, xgb_probs, mlp_probs, ensemble_probs]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, model_name in enumerate(models):\n",
    "        accuracy = accuracy_score(y_test, predictions[i])\n",
    "        precision = precision_score(y_test, predictions[i])\n",
    "        recall = recall_score(y_test, predictions[i])\n",
    "        f1 = f1_score(y_test, predictions[i])\n",
    "        auc = roc_auc_score(y_test, probabilities[i])\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'AUC': auc\n",
    "        })\n",
    "        \n",
    "        print(f\"{model_name} Test Results:\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"  Precision: {precision:.4f}\")\n",
    "        print(f\"  Recall: {recall:.4f}\")\n",
    "        print(f\"  F1 Score: {f1:.4f}\")\n",
    "        print(f\"  AUC: {auc:.4f}\\n\")\n",
    "    \n",
    "    # Convert results to DataFrame for easier comparison\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Create a heatmap of the results for visual comparison\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    heatmap_data = results_df[metrics].values\n",
    "    sns.heatmap(heatmap_data, annot=True, fmt='.4f', cmap='YlGnBu',\n",
    "                xticklabels=metrics, yticklabels=models,\n",
    "                vmin=np.min(heatmap_data) * 0.95, vmax=np.max(heatmap_data) * 1.05)\n",
    "    plt.title('Performance Metrics Comparison')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot confusion matrix for the ensemble\n",
    "    cm = confusion_matrix(y_test, ensemble_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Ensemble Meta-Learner Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"Ensemble Classification Report:\")\n",
    "    print(classification_report(y_test, ensemble_preds, target_names=['Real', 'Fake']))\n",
    "    \n",
    "    # Visualize model agreement\n",
    "    model_votes = np.vstack([svm_preds, xgb_preds, mlp_preds]).T\n",
    "    vote_counts = np.sum(model_votes, axis=1)\n",
    "    \n",
    "    agreement_counts = {\n",
    "        'Unanimous (0/3)': np.sum(vote_counts == 0),\n",
    "        'Majority (1/3)': np.sum(vote_counts == 1),\n",
    "        'Majority (2/3)': np.sum(vote_counts == 2),\n",
    "        'Unanimous (3/3)': np.sum(vote_counts == 3)\n",
    "    }\n",
    "    \n",
    "    # Visualize model agreement\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\n",
    "    plt.pie(\n",
    "        agreement_counts.values(),\n",
    "        labels=agreement_counts.keys(),\n",
    "        autopct='%1.1f%%',\n",
    "        colors=colors,\n",
    "        shadow=True,\n",
    "        startangle=90\n",
    "    )\n",
    "    plt.axis('equal')\n",
    "    plt.title('Model Agreement on Test Set')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nEnsemble Meta-Learner Summary:\")\n",
    "    print(f\"Weights - SVM: {ensemble['weights']['svm']:.3f}, XGBoost: {ensemble['weights']['xgb']:.3f}, MLP: {ensemble['weights']['mlp']:.3f}\")\n",
    "    print(f\"Test Accuracy: {results_df.loc[3, 'Accuracy']:.4f}\")\n",
    "    print(f\"Test F1 Score: {results_df.loc[3, 'F1 Score']:.4f}\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Evaluate the ensemble meta-learner\n",
    "test_results = evaluate_ensemble(ensemble_meta_learner, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c420b95",
   "metadata": {},
   "source": [
    "# Visualize Model Predictions on Test Set\n",
    "Visualize how our enhanced ensemble model performs on specific examples from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ensemble_predictions(ensemble, features, labels, file_paths, num_samples=5):\n",
    "    \"\"\"Visualize ensemble predictions with individual model contributions\"\"\"\n",
    "    import random\n",
    "    from tensorflow.keras.preprocessing.image import load_img\n",
    "    \n",
    "    # Scale features for models that need scaling\n",
    "    features_scaled = ensemble['scaler'].transform(features)\n",
    "    \n",
    "    # Get predictions from individual models\n",
    "    svm_probs = ensemble['svm'].predict_proba(features_scaled)[:, 1]\n",
    "    xgb_probs = ensemble['xgb'].predict_proba(features)[:, 1]\n",
    "    mlp_probs = ensemble['mlp'].predict(features_scaled).flatten()\n",
    "    \n",
    "    # Get ensemble predictions\n",
    "    ensemble_probs = ensemble['predict'](features, proba=True)\n",
    "    ensemble_preds = (ensemble_probs > 0.5).astype(int)\n",
    "    \n",
    "    # Find correct and incorrect predictions\n",
    "    correct_indices = np.where(ensemble_preds == labels)[0]\n",
    "    incorrect_indices = np.where(ensemble_preds != labels)[0]\n",
    "    \n",
    "    # Try to select an even mix of correct and incorrect predictions\n",
    "    num_correct = min(num_samples // 2, len(correct_indices))\n",
    "    num_incorrect = min(num_samples - num_correct, len(incorrect_indices))\n",
    "    \n",
    "    # If we don't have enough incorrect predictions, use more correct ones\n",
    "    if num_incorrect < (num_samples - num_correct):\n",
    "        num_correct = min(num_samples - num_incorrect, len(correct_indices))\n",
    "    \n",
    "    # Randomly sample indices\n",
    "    sampled_correct = random.sample(list(correct_indices), num_correct) if num_correct > 0 else []\n",
    "    sampled_incorrect = random.sample(list(incorrect_indices), num_incorrect) if num_incorrect > 0 else []\n",
    "    sampled_indices = sampled_correct + sampled_incorrect\n",
    "    random.shuffle(sampled_indices)\n",
    "    \n",
    "    # Get model weights for bar chart\n",
    "    weights = ensemble['weights']\n",
    "    svm_weight = weights['svm']\n",
    "    xgb_weight = weights['xgb']\n",
    "    mlp_weight = weights['mlp']\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(15, 5 * num_samples))\n",
    "    \n",
    "    for i, idx in enumerate(sampled_indices):\n",
    "        # Get prediction details\n",
    "        true_label = labels[idx]\n",
    "        pred_label = ensemble_preds[idx]\n",
    "        file_path = file_paths[idx]\n",
    "        \n",
    "        # Get individual model probabilities\n",
    "        svm_prob = svm_probs[idx]\n",
    "        xgb_prob = xgb_probs[idx]\n",
    "        mlp_prob = mlp_probs[idx]\n",
    "        ensemble_prob = ensemble_probs[idx]\n",
    "        \n",
    "        # Display the image\n",
    "        plt.subplot(num_samples, 2, 2*i+1)\n",
    "        try:\n",
    "            img = load_img(file_path)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Set title based on prediction correctness\n",
    "            if true_label == pred_label:\n",
    "                result = \"CORRECT\"\n",
    "                color = 'green'\n",
    "            else:\n",
    "                result = \"INCORRECT\"\n",
    "                color = 'red'\n",
    "            \n",
    "            true_text = \"Real\" if true_label == 0 else \"Fake\"\n",
    "            pred_text = \"Real\" if pred_label == 0 else \"Fake\"\n",
    "            \n",
    "            title = f\"{result}: {file_path.split('/')[-2]}\\nTrue: {true_text}, Predicted: {pred_text} (Confidence: {ensemble_prob:.4f})\"\n",
    "            plt.title(title, color=color, fontsize=12)\n",
    "            \n",
    "        except Exception as e:\n",
    "            plt.text(0.5, 0.5, f\"Error loading image: {e}\", ha='center', va='center')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        # Display bar chart of model probabilities\n",
    "        plt.subplot(num_samples, 2, 2*i+2)\n",
    "        models = ['SVM', 'XGBoost', 'MLP', 'Ensemble']\n",
    "        probs = [svm_prob, xgb_prob, mlp_prob, ensemble_prob]\n",
    "        colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\n",
    "        \n",
    "        bars = plt.bar(models, probs, color=colors)\n",
    "        \n",
    "        # Add model weights as text\n",
    "        plt.text(0, 1.05, f\"w={svm_weight:.2f}\", ha='center')\n",
    "        plt.text(1, 1.05, f\"w={xgb_weight:.2f}\", ha='center')\n",
    "        plt.text(2, 1.05, f\"w={mlp_weight:.2f}\", ha='center')\n",
    "        \n",
    "        # Add decision threshold line\n",
    "        plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add value labels on top of bars\n",
    "        for j, prob in enumerate(probs):\n",
    "            plt.text(j, prob + 0.03, f\"{prob:.3f}\", ha='center')\n",
    "        \n",
    "        plt.ylim(0, 1.1)\n",
    "        plt.ylabel('Probability of Fake')\n",
    "        plt.title('Model Predictions')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.4)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize ensemble predictions on test set\n",
    "test_file_paths = test_generator_xception.filepaths\n",
    "print(\"Visualizing ensemble predictions on test set...\")\n",
    "visualize_ensemble_predictions(ensemble_meta_learner, test_features, test_labels, test_file_paths, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2905a03",
   "metadata": {},
   "source": [
    "# Robustness Testing with Enhanced Ensemble\n",
    "Test the enhanced ensemble model's robustness to variations in brightness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2adae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_ensemble_robustness(ensemble, selected_indices, test_dir):\n",
    "    \"\"\"Test ensemble robustness to variations in brightness\"\"\"\n",
    "    print(\"Testing ensemble robustness to brightness variations...\")\n",
    "    \n",
    "    # Create feature extractors\n",
    "    xception_extractor = create_feature_extractor('xception', IMAGE_SIZE)\n",
    "    efficientnet_extractor = create_feature_extractor('efficientnetv2', IMAGE_SIZE)\n",
    "    \n",
    "    # Brightness variations to test\n",
    "    brightness_variations = [0.5, 0.75, 1.0, 1.25, 1.5]\n",
    "    results = []\n",
    "    \n",
    "    for brightness in brightness_variations:\n",
    "        print(f\"\\nTesting with brightness factor: {brightness}\")\n",
    "        \n",
    "        # Create test generators with brightness adjustment\n",
    "        test_brightness_datagen_xception = ImageDataGenerator(\n",
    "            preprocessing_function=xception_preprocess,\n",
    "            brightness_range=[brightness, brightness]\n",
    "        )\n",
    "        \n",
    "        test_brightness_gen_xception = test_brightness_datagen_xception.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='binary',\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Extract Xception features\n",
    "        x_features, test_labels = extract_features(xception_extractor, test_brightness_gen_xception, f'Xception-{brightness}')\n",
    "        \n",
    "        # Create EfficientNetV2L generator with brightness adjustment\n",
    "        test_brightness_datagen_efficientnet = ImageDataGenerator(\n",
    "            preprocessing_function=efficientnetv2_preprocess,\n",
    "            brightness_range=[brightness, brightness]\n",
    "        )\n",
    "        \n",
    "        test_brightness_gen_efficientnet = test_brightness_datagen_efficientnet.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='binary',\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Extract EfficientNetV2L features\n",
    "        e_features, _ = extract_features(efficientnet_extractor, test_brightness_gen_efficientnet, f'EfficientNetV2L-{brightness}')\n",
    "        \n",
    "        # Stack features\n",
    "        stacked_features = np.concatenate([x_features, e_features], axis=1)\n",
    "        \n",
    "        # Apply feature selection\n",
    "        features_selected = stacked_features[:, selected_indices]\n",
    "        \n",
    "        # Make ensemble predictions\n",
    "        ensemble_preds = ensemble['predict'](features_selected)\n",
    "        ensemble_probs = ensemble['predict'](features_selected, proba=True)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(test_labels, ensemble_preds)\n",
    "        precision = precision_score(test_labels, ensemble_preds)\n",
    "        recall = recall_score(test_labels, ensemble_preds)\n",
    "        f1 = f1_score(test_labels, ensemble_preds)\n",
    "        auc = roc_auc_score(test_labels, ensemble_probs)\n",
    "        \n",
    "        results.append({\n",
    "            'Brightness': brightness,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1 Score': f1,\n",
    "            'AUC': auc\n",
    "        })\n",
    "        \n",
    "        print(f\"Brightness {brightness} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC']\n",
    "    colors = ['#4CAF50', '#2196F3', '#FFC107', '#9C27B0', '#F44336']\n",
    "    markers = ['o', 's', '^', 'D', '*']\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.plot(\n",
    "            df_results['Brightness'],\n",
    "            df_results[metric],\n",
    "            marker=markers[i],\n",
    "            color=colors[i],\n",
    "            label=metric,\n",
    "            linewidth=2,\n",
    "            markersize=10\n",
    "        )\n",
    "    \n",
    "    plt.xlabel('Brightness Factor', fontsize=12)\n",
    "    plt.ylabel('Score', fontsize=12)\n",
    "    plt.title('Ensemble Robustness to Brightness Variations', fontsize=14)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xticks(brightness_variations)\n",
    "    plt.ylim(0.5, 1.0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show the results table\n",
    "    print(\"\\nRobustness Test Results:\")\n",
    "    display(df_results.style.format({col: '{:.4f}' for col in df_results.columns if col != 'Brightness'}))\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "# Run the robustness test on the ensemble meta-learner\n",
    "robustness_results = test_ensemble_robustness(ensemble_meta_learner, selected_indices, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c9dff6",
   "metadata": {},
   "source": [
    "# Save Enhanced Ensemble Model\n",
    "Save the enhanced ensemble meta-learner and its components for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ensemble_model(ensemble, selected_indices, output_dir='/content/enhanced_ensemble'):\n",
    "    \"\"\"Save the ensemble model components and metadata\"\"\"\n",
    "    import joblib\n",
    "    import json\n",
    "    import os\n",
    "    \n",
    "    print(f\"Saving enhanced ensemble model to {output_dir}...\")\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save SVM model\n",
    "    joblib.dump(ensemble['svm'], f\"{output_dir}/svm_model.pkl\")\n",
    "    \n",
    "    # Save XGBoost model\n",
    "    joblib.dump(ensemble['xgb'], f\"{output_dir}/xgb_model.pkl\")\n",
    "    \n",
    "    # Save MLP model\n",
    "    ensemble['mlp'].save(f\"{output_dir}/mlp_model\")\n",
    "    \n",
    "    # Save feature scaler\n",
    "    joblib.dump(ensemble['scaler'], f\"{output_dir}/feature_scaler.pkl\")\n",
    "    \n",
    "    # Save selected feature indices\n",
    "    np.save(f\"{output_dir}/selected_indices.npy\", selected_indices)\n",
    "    \n",
    "    # Save model weights\n",
    "    with open(f\"{output_dir}/model_weights.json\", 'w') as f:\n",
    "        json.dump(ensemble['weights'], f)\n",
    "    \n",
    "    # Save a README file with instructions\n",
    "    readme = \"\"\"# Enhanced Ensemble Meta-Learner for Deepfake Detection\n",
    "\n",
    "This directory contains the saved components of an enhanced ensemble meta-learner for deepfake detection.\n",
    "\n",
    "## Model Components\n",
    "- `svm_model.pkl`: Calibrated SVM model\n",
    "- `xgb_model.pkl`: Calibrated XGBoost model\n",
    "- `mlp_model/`: TensorFlow MLP model directory\n",
    "- `feature_scaler.pkl`: StandardScaler for feature normalization\n",
    "- `selected_indices.npy`: Indices of selected features\n",
    "- `model_weights.json`: Ensemble voting weights\n",
    "\n",
    "## Usage Example\n",
    "```python\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load model components\n",
    "svm = joblib.load('svm_model.pkl')\n",
    "xgb = joblib.load('xgb_model.pkl')\n",
    "mlp = load_model('mlp_model')\n",
    "scaler = joblib.load('feature_scaler.pkl')\n",
    "selected_indices = np.load('selected_indices.npy')\n",
    "\n",
    "# Load weights\n",
    "with open('model_weights.json', 'r') as f:\n",
    "    weights = json.load(f)\n",
    "\n",
    "# Define prediction function\n",
    "def ensemble_predict(features, proba=False):\n",
    "    # Scale features\n",
    "    features_scaled = scaler.transform(features)\n",
    "    \n",
    "    # Get probabilities from each model\n",
    "    svm_probs = svm.predict_proba(features_scaled)[:, 1]\n",
    "    xgb_probs = xgb.predict_proba(features)[:, 1]\n",
    "    mlp_probs = mlp.predict(features_scaled).flatten()\n",
    "    \n",
    "    # Apply weighted average\n",
    "    weighted_probs = (\n",
    "        weights['svm'] * svm_probs +\n",
    "        weights['xgb'] * xgb_probs +\n",
    "        weights['mlp'] * mlp_probs\n",
    "    )\n",
    "    \n",
    "    if proba:\n",
    "        return weighted_probs\n",
    "    else:\n",
    "        return (weighted_probs > 0.5).astype(int)\n",
    "```\n",
    "\"\"\"\n",
    "    \n",
    "    with open(f\"{output_dir}/README.md\", 'w') as f:\n",
    "        f.write(readme)\n",
    "    \n",
    "    print(f\"Enhanced ensemble model saved successfully to {output_dir}\")\n",
    "    \n",
    "    # For Google Colab: Create a downloadable zip file\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        !zip -r /content/enhanced_ensemble.zip {output_dir}\n",
    "        files.download('/content/enhanced_ensemble.zip')\n",
    "        print(\"\\nDownload initiated for enhanced_ensemble.zip\")\n",
    "    except (ImportError, NameError):\n",
    "        print(\"\\nNot running in Google Colab, files saved locally only\")\n",
    "\n",
    "# Save the enhanced ensemble model\n",
    "save_ensemble_model(ensemble_meta_learner, selected_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5fad5e",
   "metadata": {},
   "source": [
    "# Evaluate the Model\n",
    "Evaluate the model's performance on the test dataset and visualize metrics such as accuracy and loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54728deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_meta_learner(model, X_test, y_test):\n",
    "    \"\"\"Evaluate meta-learner on test set with comprehensive metrics\"\"\"\n",
    "    print(\"Evaluating meta-learner...\")\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_prob)\n",
    "    \n",
    "    print(f\"Meta-learner Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Meta-learner Test Precision: {precision:.4f}\")\n",
    "    print(f\"Meta-learner Test Recall: {recall:.4f}\")\n",
    "    print(f\"Meta-learner Test F1 Score: {f1:.4f}\")\n",
    "    print(f\"Meta-learner Test ROC AUC: {auc:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Meta-learner Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Classification Report\n",
    "    print(\"Meta-learner Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Real', 'Fake']))\n",
    "    \n",
    "    return accuracy, precision, recall, f1, auc\n",
    "\n",
    "# Evaluate the model with comprehensive metrics\n",
    "metrics = evaluate_meta_learner(meta_learner, test_features, test_labels)\n",
    "\n",
    "# Compare with baseline models if available (optional)\n",
    "if 'xception_model' in globals() and 'efficientnet_model' in globals():\n",
    "    print(\"\\nComparing with base models performance:\")\n",
    "    models = ['Meta-Learner']\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Model': models,\n",
    "        'Accuracy': [metrics[0]],\n",
    "        'Precision': [metrics[1]],\n",
    "        'Recall': [metrics[2]],\n",
    "        'F1 Score': [metrics[3]],\n",
    "        'AUC': [metrics[4]]\n",
    "    })\n",
    "    \n",
    "    print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0f7d2e",
   "metadata": {},
   "source": [
    "# Visualize Model Predictions on Validation Set\n",
    "Let's visualize how our model performs on the validation set to get a better understanding of its strengths and weaknesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a0c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting validation file paths\n",
    "val_file_paths = val_generator.filepaths\n",
    "\n",
    "print(\"Visualizing sample predictions on validation set...\")\n",
    "visualize_sample_predictions(meta_learner, val_features, val_labels, val_file_paths, num_samples=5)\n",
    "\n",
    "# Optional: You can also see more examples by increasing the number of samples\n",
    "# Uncomment the line below to see 10 examples instead\n",
    "# visualize_sample_predictions(meta_learner, val_features, val_labels, val_file_paths, num_samples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b207c18b",
   "metadata": {},
   "source": [
    "# Visualize Model Predictions on Test Set\n",
    "Let's also visualize how our model performs on the test set to assess its generalization capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe45496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting test file paths\n",
    "test_file_paths = test_generator.filepaths\n",
    "\n",
    "print(\"Visualizing sample predictions on test set...\")\n",
    "visualize_sample_predictions(meta_learner, test_features, test_labels, test_file_paths, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a19eea",
   "metadata": {},
   "source": [
    "# Sample Model Predictions\n",
    "Visualize a few sample predictions from our model to see how well it's performing on specific examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a878bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_predictions(model, features, labels, true_file_paths, num_samples=5):\n",
    "    \"\"\"Visualize sample predictions from the model with original images\"\"\"\n",
    "    import random\n",
    "    import cv2\n",
    "    from tensorflow.keras.preprocessing.image import load_img\n",
    "    \n",
    "    # Generate predictions for all samples\n",
    "    pred_probs = model.predict(features)\n",
    "    predictions = (pred_probs > 0.5).astype(int).flatten()\n",
    "    \n",
    "    # Find correct and incorrect predictions\n",
    "    correct_indices = np.where(predictions == labels)[0]\n",
    "    incorrect_indices = np.where(predictions != labels)[0]\n",
    "    \n",
    "    # Try to get an even mix of correct and incorrect predictions if possible\n",
    "    num_correct = min(num_samples // 2 + num_samples % 2, len(correct_indices))\n",
    "    num_incorrect = min(num_samples // 2, len(incorrect_indices))\n",
    "    \n",
    "    # If we don't have enough incorrect predictions, use more correct ones\n",
    "    if num_incorrect < num_samples // 2:\n",
    "        num_correct = min(num_samples - num_incorrect, len(correct_indices))\n",
    "    \n",
    "    # If we don't have enough correct predictions, use more incorrect ones\n",
    "    if num_correct < num_samples // 2 + num_samples % 2:\n",
    "        num_incorrect = min(num_samples - num_correct, len(incorrect_indices))\n",
    "    \n",
    "    # Randomly sample from correct and incorrect predictions\n",
    "    sampled_correct = random.sample(list(correct_indices), num_correct) if num_correct > 0 else []\n",
    "    sampled_incorrect = random.sample(list(incorrect_indices), num_incorrect) if num_incorrect > 0 else []\n",
    "    \n",
    "    # Combine the samples\n",
    "    sampled_indices = sampled_correct + sampled_incorrect\n",
    "    random.shuffle(sampled_indices)  # Shuffle to mix correct and incorrect predictions\n",
    "    \n",
    "    # Limit to the requested number of samples\n",
    "    sampled_indices = sampled_indices[:num_samples]\n",
    "    \n",
    "    # Create a figure to display the results\n",
    "    plt.figure(figsize=(12, 4 * num_samples))\n",
    "    \n",
    "    for i, idx in enumerate(sampled_indices):\n",
    "        # Get the prediction details\n",
    "        true_label = labels[idx]\n",
    "        pred_label = predictions[idx]\n",
    "        prob = pred_probs[idx][0]\n",
    "        \n",
    "        # Get the corresponding file path\n",
    "        file_path = true_file_paths[idx]\n",
    "        \n",
    "        # Load the image\n",
    "        try:\n",
    "            img = load_img(file_path)\n",
    "            plt.subplot(num_samples, 1, i+1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Set title based on prediction correctness\n",
    "            if true_label == pred_label:\n",
    "                result = \"CORRECT\"\n",
    "                color = 'green'\n",
    "            else:\n",
    "                result = \"INCORRECT\"\n",
    "                color = 'red'\n",
    "                \n",
    "            true_text = \"Real\" if true_label == 0 else \"Fake\"\n",
    "            pred_text = \"Real\" if pred_label == 0 else \"Fake\"\n",
    "            \n",
    "            title = f\"{result}: {file_path.split('/')[-2]}\\nTrue: {true_text}, Predicted: {pred_text} (Confidence: {prob:.4f})\"\n",
    "            plt.title(title, color=color, fontsize=12)\n",
    "            \n",
    "        except Exception as e:\n",
    "            plt.subplot(num_samples, 1, i+1)\n",
    "            plt.text(0.5, 0.5, f\"Error loading image: {e}\", ha='center', va='center')\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6247fa",
   "metadata": {},
   "source": [
    "# Robustness Testing\n",
    "Test the model's robustness to variations in brightness as mentioned in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d8b817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_robustness(meta_learner, selected_indices, test_dir):\n",
    "    \"\"\"Test model robustness with brightness variations as mentioned in the paper\"\"\"\n",
    "    print(\"Testing model robustness to brightness variations...\")\n",
    "    \n",
    "    # Create feature extractors\n",
    "    xception_extractor = create_feature_extractor('xception', IMAGE_SIZE)\n",
    "    efficientnet_extractor = create_feature_extractor('efficientnetv2', IMAGE_SIZE)\n",
    "    \n",
    "    # Create data generators with brightness variations\n",
    "    brightness_variations = [0.5, 0.75, 1.0, 1.25, 1.5]  # 50%, 75%, 100%, 125%, 150%\n",
    "    results = []\n",
    "    \n",
    "    for brightness in brightness_variations:\n",
    "        print(f\"Testing with brightness factor: {brightness}\")\n",
    "        \n",
    "        # Create a test generator with brightness adjustment\n",
    "        test_brightness_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=xception_preprocess,\n",
    "            brightness_range=[brightness, brightness]\n",
    "        )\n",
    "        \n",
    "        test_brightness_gen = test_brightness_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='binary',\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Extract features for Xception\n",
    "        test_x_features, test_labels = extract_features(xception_extractor, test_brightness_gen, f'Xception Brightness-{brightness}')\n",
    "        \n",
    "        # Reset generator for EfficientNet\n",
    "        test_brightness_gen = test_brightness_datagen.flow_from_directory(\n",
    "            test_dir,\n",
    "            target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            class_mode='binary',\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Extract features for EfficientNet\n",
    "        test_e_features, _ = extract_features(efficientnet_extractor, test_brightness_gen, f'EfficientNet Brightness-{brightness}')\n",
    "        \n",
    "        # Stack features\n",
    "        test_stacked = np.concatenate([test_x_features, test_e_features], axis=1)\n",
    "        \n",
    "        # Apply feature selection\n",
    "        # Create feature mask\n",
    "        feature_mask = np.zeros(test_stacked.shape[1], dtype=bool)\n",
    "        feature_mask[selected_indices] = True\n",
    "        \n",
    "        # Select features\n",
    "        test_selected = test_stacked[:, feature_mask]\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = (meta_learner.predict(test_selected) > 0.5).astype(\"int32\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(test_labels, y_pred)\n",
    "        precision = precision_score(test_labels, y_pred)\n",
    "        recall = recall_score(test_labels, y_pred)\n",
    "        f1 = f1_score(test_labels, y_pred)\n",
    "        \n",
    "        results.append({\n",
    "            'brightness': brightness,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1\n",
    "        })\n",
    "        \n",
    "        print(f\"Brightness {brightness} - Accuracy: {accuracy:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    # Convert results to DataFrame for easier analysis\n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df_results['brightness'], df_results['accuracy'], 'o-', label='Accuracy')\n",
    "    plt.plot(df_results['brightness'], df_results['f1_score'], 's-', label='F1 Score')\n",
    "    plt.plot(df_results['brightness'], df_results['precision'], '^-', label='Precision')\n",
    "    plt.plot(df_results['brightness'], df_results['recall'], 'd-', label='Recall')\n",
    "    plt.xlabel('Brightness Factor')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Robustness to Brightness Variations')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display results as a table\n",
    "    print(\"\\nRobustness Test Results:\")\n",
    "    print(df_results.round(4))\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "# Run robustness test\n",
    "# Comment out the next line if you want to skip this test during initial development\n",
    "robustness_results = test_model_robustness(meta_learner, selected_indices, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8633e91",
   "metadata": {},
   "source": [
    "# Save and Export Results\n",
    "Save the trained model and export results such as predictions or performance metrics to Google Drive or a downloadable file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c6c5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, evaluate the model to get metrics\n",
    "print(\"Evaluating model on test set to get final metrics...\")\n",
    "# Get predictions\n",
    "test_predictions = (meta_learner.predict(test_features) > 0.5).astype(\"int32\")\n",
    "test_pred_prob = meta_learner.predict(test_features)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "precision = precision_score(test_labels, test_predictions)\n",
    "recall = recall_score(test_labels, test_predictions)\n",
    "f1 = f1_score(test_labels, test_predictions)\n",
    "auc = roc_auc_score(test_labels, test_pred_prob)\n",
    "\n",
    "metrics = [accuracy, precision, recall, f1, auc]\n",
    "print(f\"Final metrics - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "\n",
    "# Save the trained model and feature selection indices\n",
    "# Create a directory for saved models if it doesn't exist\n",
    "os.makedirs('/content/saved_models', exist_ok=True)\n",
    "\n",
    "# Save the meta-learner model\n",
    "meta_learner.save('/content/saved_models/meta_learner_model.h5')\n",
    "\n",
    "# Save the selected feature indices\n",
    "np.save('/content/saved_models/selected_feature_indices.npy', selected_indices)\n",
    "\n",
    "# Export predictions to CSV\n",
    "np.savetxt('/content/saved_models/test_predictions.csv', test_predictions, delimiter=',', fmt='%d')\n",
    "\n",
    "# Save performance metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC'],\n",
    "    'Score': metrics\n",
    "})\n",
    "metrics_df.to_csv('/content/saved_models/performance_metrics.csv', index=False)\n",
    "\n",
    "print(\"Model, predictions, and metrics saved successfully to '/content/saved_models' directory\")\n",
    "\n",
    "# For Google Colab: Download files to local machine\n",
    "try:\n",
    "    from google.colab import files\n",
    "    # Compress the saved_models directory\n",
    "    !zip -r /content/saved_models.zip /content/saved_models\n",
    "    # Download the zip file\n",
    "    files.download('/content/saved_models.zip')\n",
    "    print(\"\\nDownload initiated for saved_models.zip\")\n",
    "except ImportError:\n",
    "    print(\"\\nNot running in Google Colab, files saved locally only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ce5009",
   "metadata": {},
   "source": [
    "# Inference on New Data\n",
    "Run inference on new images or videos to detect deepfakes using our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a94ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_on_new_data(image_path=None, video_path=None, model_path='/content/saved_models/meta_learner_model.h5', indices_path='/content/saved_models/selected_feature_indices.npy'):\n",
    "    \"\"\"Function to run inference on new images or videos\"\"\"\n",
    "    if image_path is None and video_path is None:\n",
    "        print(\"Please provide either an image path or a video path\")\n",
    "        return\n",
    "    \n",
    "    # Load the meta-learner model\n",
    "    try:\n",
    "        from tensorflow.keras.models import load_model\n",
    "        meta_learner = load_model(model_path)\n",
    "        selected_indices = np.load(indices_path)\n",
    "        print(f\"Loaded model from {model_path} and selected features from {indices_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {e}\")\n",
    "        print(\"Please ensure the model and feature indices files exist\")\n",
    "        return\n",
    "    \n",
    "    # Create feature extractors\n",
    "    xception_extractor = create_feature_extractor('xception', IMAGE_SIZE)\n",
    "    efficientnet_extractor = create_feature_extractor('efficientnetv2', IMAGE_SIZE)\n",
    "    \n",
    "    if image_path:\n",
    "        process_image(image_path, xception_extractor, efficientnet_extractor, meta_learner, selected_indices)\n",
    "    elif video_path:\n",
    "        process_video(video_path, xception_extractor, efficientnet_extractor, meta_learner, selected_indices)\n",
    "\n",
    "def process_image(image_path, xception_extractor, efficientnet_extractor, meta_learner, selected_indices):\n",
    "    \"\"\"Process a single image for deepfake detection\"\"\"\n",
    "    from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "    import time\n",
    "    \n",
    "    print(f\"Processing image: {image_path}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    img = load_img(image_path, target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = xception_preprocess(img_array)\n",
    "    \n",
    "    # Extract features\n",
    "    xception_features = xception_extractor.predict(img_array, verbose=0)\n",
    "    efficientnet_features = efficientnet_extractor.predict(img_array, verbose=0)\n",
    "    \n",
    "    # Stack features\n",
    "    stacked_features = np.concatenate([xception_features, efficientnet_features], axis=1)\n",
    "    \n",
    "    # Apply feature selection\n",
    "    feature_mask = np.zeros(stacked_features.shape[1], dtype=bool)\n",
    "    feature_mask[selected_indices] = True\n",
    "    selected_features = stacked_features[:, feature_mask]\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction_prob = meta_learner.predict(selected_features, verbose=0)[0][0]\n",
    "    prediction = 1 if prediction_prob > 0.5 else 0\n",
    "    \n",
    "    # Calculate processing time\n",
    "    process_time = time.time() - start_time\n",
    "    \n",
    "    # Display result\n",
    "    label = \"Fake\" if prediction == 1 else \"Real\"\n",
    "    confidence = prediction_prob if prediction == 1 else 1 - prediction_prob\n",
    "    print(f\"Prediction: {label} (confidence: {confidence:.4f})\")\n",
    "    print(f\"Processing time: {process_time:.2f} seconds\")\n",
    "    \n",
    "    # Display the image with prediction\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(load_img(image_path))\n",
    "    plt.title(f\"Prediction: {label} (confidence: {confidence:.4f})\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return label, confidence\n",
    "\n",
    "def process_video(video_path, xception_extractor, efficientnet_extractor, meta_learner, selected_indices):\n",
    "    \"\"\"Process a video for deepfake detection\"\"\"\n",
    "    import cv2\n",
    "    from tqdm.notebook import tqdm\n",
    "    import time\n",
    "    \n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    duration = frame_count / fps\n",
    "    \n",
    "    print(f\"Video info - Frames: {frame_count}, FPS: {fps:.2f}, Duration: {duration:.2f}s\")\n",
    "    \n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    frames_to_show = []\n",
    "    \n",
    "    # Process frames at regular intervals (analyze ~20 frames throughout the video)\n",
    "    interval = max(1, frame_count // 20)\n",
    "    frames_to_process = range(0, frame_count, interval)\n",
    "    \n",
    "    for i in tqdm(frames_to_process, desc=\"Processing video frames\"):\n",
    "        # Set the position of the next frame to read\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            print(f\"Failed to read frame {i}\")\n",
    "            continue\n",
    "        \n",
    "        # Convert frame from BGR to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Save a few frames to display later\n",
    "        if len(frames_to_show) < 4 and i % (interval * 4) == 0:\n",
    "            frames_to_show.append((i, frame_rgb.copy()))\n",
    "        \n",
    "        # Resize frame\n",
    "        frame_resized = cv2.resize(frame_rgb, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        \n",
    "        # Preprocess frame\n",
    "        frame_array = np.expand_dims(frame_resized, axis=0)\n",
    "        frame_array = xception_preprocess(frame_array)\n",
    "        \n",
    "        # Extract features\n",
    "        xception_features = xception_extractor.predict(frame_array, verbose=0)\n",
    "        efficientnet_features = efficientnet_extractor.predict(frame_array, verbose=0)\n",
    "        \n",
    "        # Stack features\n",
    "        stacked_features = np.concatenate([xception_features, efficientnet_features], axis=1)\n",
    "        \n",
    "        # Apply feature selection\n",
    "        feature_mask = np.zeros(stacked_features.shape[1], dtype=bool)\n",
    "        feature_mask[selected_indices] = True\n",
    "        selected_features = stacked_features[:, feature_mask]\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction_prob = meta_learner.predict(selected_features, verbose=0)[0][0]\n",
    "        prediction = 1 if prediction_prob > 0.5 else 0\n",
    "        \n",
    "        # Save results\n",
    "        predictions.append(prediction)\n",
    "        probabilities.append(prediction_prob)\n",
    "    \n",
    "    # Close the video file\n",
    "    cap.release()\n",
    "    \n",
    "    # Calculate final prediction and metrics\n",
    "    final_prediction = 1 if sum(predictions) / len(predictions) > 0.5 else 0\n",
    "    final_probability = sum(probabilities) / len(probabilities)\n",
    "    processing_time = time.time() - start_time\n",
    "    \n",
    "    # Display result\n",
    "    label = \"Fake\" if final_prediction == 1 else \"Real\"\n",
    "    confidence = final_probability if final_prediction == 1 else 1 - final_probability\n",
    "    print(f\"Video prediction: {label} (confidence: {confidence:.4f})\")\n",
    "    print(f\"Processing time: {processing_time:.2f} seconds\")\n",
    "    \n",
    "    # Display sample frames\n",
    "    if frames_to_show:\n",
    "        plt.figure(figsize=(16, 4 * len(frames_to_show) // 2))\n",
    "        for idx, (frame_idx, frame) in enumerate(frames_to_show):\n",
    "            plt.subplot(len(frames_to_show) // 2 + len(frames_to_show) % 2, 2, idx + 1)\n",
    "            plt.imshow(frame)\n",
    "            time_point = frame_idx / fps\n",
    "            plt.title(f\"Frame {frame_idx} (Time: {time_point:.2f}s)\")\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot predictions over time\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    time_points = [i / fps for i in frames_to_process[:len(probabilities)]]\n",
    "    plt.plot(time_points, probabilities, 'o-', markersize=4, label='Frame Predictions')\n",
    "    plt.axhline(y=0.5, color='r', linestyle='--', label='Decision Threshold')\n",
    "    plt.axhline(y=final_probability, color='g', linestyle='-', label='Average Prediction')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Probability of Fake')\n",
    "    plt.title(f\"Video Classification: {label} (confidence: {confidence:.4f})\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return label, confidence\n",
    "\n",
    "# Example usage (uncomment to use)\n",
    "# inference_on_new_data(image_path='/content/PreprocessedDatasetV1/test/real/example.jpg')  # For single image\n",
    "# inference_on_new_data(video_path='/content/example_video.mp4')  # For video"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
