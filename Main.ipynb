{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0yoEIuThF67"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create a dataset directory\n",
        "os.makedirs('/content/dataset', exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To divide the dataset into test, train and validate"
      ],
      "metadata": {
        "id": "gaL2omYydwnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define paths\n",
        "dataset_path = \"/content/dataset\"\n",
        "preprocessed_real_path = os.path.join(dataset_path, \"Preprocessed-images\", \"Celeb-real\")\n",
        "preprocessed_fake_path = os.path.join(dataset_path, \"Preprocessed-images\", \"Celeb-synthesis\")\n",
        "\n",
        "# Output directories\n",
        "train_dir = os.path.join(dataset_path, \"train\")\n",
        "val_dir = os.path.join(dataset_path, \"validation\")\n",
        "test_dir = os.path.join(dataset_path, \"test\")\n",
        "\n",
        "# Ensure train/val/test directories exist\n",
        "for split in [train_dir, val_dir, test_dir]:\n",
        "    os.makedirs(f\"{split}/real\", exist_ok=True)\n",
        "    os.makedirs(f\"{split}/fake\", exist_ok=True)\n",
        "\n",
        "# Get list of images\n",
        "all_real_images = os.listdir(preprocessed_real_path)\n",
        "all_fake_images = os.listdir(preprocessed_fake_path)\n",
        "\n",
        "# Shuffle datasets\n",
        "random.shuffle(all_real_images)\n",
        "random.shuffle(all_fake_images)\n",
        "\n",
        "# Splitting ratio\n",
        "train_ratio, val_ratio = 0.8, 0.1\n",
        "train_real = int(len(all_real_images) * train_ratio)\n",
        "val_real = int(len(all_real_images) * val_ratio)\n",
        "\n",
        "train_fake = int(len(all_fake_images) * train_ratio)\n",
        "val_fake = int(len(all_fake_images) * val_ratio)\n",
        "\n",
        "# Function to move images\n",
        "def move_images(image_list, src_folder, dest_folder, label):\n",
        "    for img in image_list:\n",
        "        src = os.path.join(src_folder, img)\n",
        "        dst = os.path.join(dest_folder, label, img)\n",
        "        shutil.move(src, dst)\n",
        "\n",
        "# Move Real Images\n",
        "move_images(all_real_images[:train_real], preprocessed_real_path, train_dir, \"real\")\n",
        "move_images(all_real_images[train_real:train_real + val_real], preprocessed_real_path, val_dir, \"real\")\n",
        "move_images(all_real_images[train_real + val_real:], preprocessed_real_path, test_dir, \"real\")\n",
        "\n",
        "# Move Fake Images\n",
        "move_images(all_fake_images[:train_fake], preprocessed_fake_path, train_dir, \"fake\")\n",
        "move_images(all_fake_images[train_fake:train_fake + val_fake], preprocessed_fake_path, val_dir, \"fake\")\n",
        "move_images(all_fake_images[train_fake + val_fake:], preprocessed_fake_path, test_dir, \"fake\")\n",
        "\n",
        "print(\"Dataset organized successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zOpwm6tkKU7",
        "outputId": "08099709-69f0-4eb7-f679-0e31db2f4166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset organized successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To resize all images into valid format"
      ],
      "metadata": {
        "id": "5rh4sv27d6fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_image(image_path, target_size=(299, 299)):\n",
        "    \"\"\"Resize and normalize image.\"\"\"\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, target_size)\n",
        "    img = img / 255.0  # Normalize to [0, 1]\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "tMVB1ZWw78yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Error handling for missed files\n"
      ],
      "metadata": {
        "id": "ajWyG_lCeF26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_images(directory):\n",
        "    return len(os.listdir(directory))\n",
        "\n",
        "print(\"Training set: Real:\", count_images(f\"{train_dir}/real\"), \" Fake:\", count_images(f\"{train_dir}/fake\"))\n",
        "print(\"Validation set: Real:\", count_images(f\"{val_dir}/real\"), \" Fake:\", count_images(f\"{val_dir}/fake\"))\n",
        "print(\"Test set: Real:\", count_images(f\"{test_dir}/real\"), \" Fake:\", count_images(f\"{test_dir}/fake\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-pw-19N9Wat",
        "outputId": "4cdb45ac-a307-4c6c-9563-e6baa7a89418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: Real: 7745  Fake: 4229\n",
            "Validation set: Real: 968  Fake: 528\n",
            "Test set: Real: 969  Fake: 530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "real_videos_path = [\"/content/dataset/Celeb-real\", \"/content/dataset/Youtube-real\"]\n",
        "\n",
        "for path in real_videos_path:\n",
        "    if os.path.exists(path):\n",
        "        print(f\"{path}: {len(os.listdir(path))} videos\")\n",
        "    else:\n",
        "        print(f\"{path} does not exist!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5lMS5109q8Z",
        "outputId": "42b1a0fb-3a36-4f51-9608-d3b0754bc09a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset/Celeb-real: 590 videos\n",
            "/content/dataset/Youtube-real: 300 videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = \"/content/dataset\"\n",
        "zip_path = \"/content/dataset.zip\"\n",
        "\n",
        "# Zip the dataset\n",
        "shutil.make_archive(zip_path.replace(\".zip\", \"\"), 'zip', dataset_path)\n",
        "\n",
        "print(f\"Dataset zipped successfully at {zip_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lsnyvIf02PO",
        "outputId": "9c77ece9-eab0-42fb-be76-9abd4d73e7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset zipped successfully at /content/dataset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the zip file\n",
        "files.download(zip_path)"
      ],
      "metadata": {
        "id": "Exg0zWAp1504",
        "outputId": "be81f5fc-eea4-4690-eadc-381178aa43fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9db5979f-ed79-46f9-b46b-04e6b58e87b1\", \"dataset.zip\", 1711389033)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Processing setup\n"
      ],
      "metadata": {
        "id": "nB0fTRwXeQDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7BfXonYHhBs",
        "outputId": "16b7fd03-683a-4628-cc75-a57db7ed6228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install insightface torchvision tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCHhe4B5Hlrf",
        "outputId": "72d69dc6-2375-4531-db66-0778eea0be6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: insightface in /usr/local/lib/python3.11/dist-packages (0.7.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from insightface) (1.26.4)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from insightface) (1.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from insightface) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from insightface) (11.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from insightface) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from insightface) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from insightface) (0.25.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from insightface) (3.0.12)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (from insightface) (2.0.5)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.11/dist-packages (from insightface) (3.15.1)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1->torchvision)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1->torchvision)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1->torchvision)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1->torchvision)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1->torchvision)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1->torchvision)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (2.10.6)\n",
            "Requirement already satisfied: albucore==0.0.23 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (0.0.23)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations->insightface) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations->insightface) (3.12.2)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations->insightface) (6.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->insightface) (2.8.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->insightface) (4.25.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prettytable->insightface) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->insightface) (2025.1.31)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (2025.2.18)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->insightface) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->insightface) (3.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations->insightface) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1->torchvision) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RetinaFace CNN for face detection of real videos"
      ],
      "metadata": {
        "id": "353X9RxieXYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "from insightface.app import FaceAnalysis\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "# Check if CUDA (GPU) is available, else fallback to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Initialize InsightFace RetinaFace with GPU support\n",
        "face_detector = FaceAnalysis(name=\"buffalo_l\", providers=[\"CUDAExecutionProvider\"])\n",
        "face_detector.prepare(ctx_id=0)  # ✅ Set to GPU\n",
        "\n",
        "# Define target size (Xception requires 299x299)\n",
        "TARGET_SIZE = (299, 299)\n",
        "\n",
        "# Torchvision transform for resizing and padding\n",
        "def resize_with_padding(image, target_size):\n",
        "    \"\"\"Resize image while maintaining aspect ratio with padding.\"\"\"\n",
        "    transform = T.Compose([\n",
        "        T.Resize(target_size, interpolation=T.InterpolationMode.BILINEAR),\n",
        "        T.CenterCrop(target_size),\n",
        "        T.ToTensor()\n",
        "    ])\n",
        "    return transform(image)\n",
        "\n",
        "def detect_and_save_faces(frame, frame_index, video_path, save_dir):\n",
        "    \"\"\"Detect faces in a single frame using RetinaFace and save cropped images.\"\"\"\n",
        "    frame_np = np.array(frame)\n",
        "    h, w, _ = frame_np.shape\n",
        "\n",
        "    # Detect faces using RetinaFace\n",
        "    faces = face_detector.get(frame_np)\n",
        "\n",
        "    if faces:\n",
        "        for face in faces:\n",
        "            x1, y1, x2, y2 = face.bbox.astype(int)\n",
        "\n",
        "            # Ensure bounding box stays within frame\n",
        "            x1, y1 = max(0, x1), max(0, y1)\n",
        "            x2, y2 = min(w, x2), min(h, y2)\n",
        "\n",
        "            # Extract and process face region\n",
        "            if x2 > x1 and y2 > y1:\n",
        "                face_crop = frame_np[y1:y2, x1:x2]\n",
        "                face_pil = Image.fromarray(face_crop)\n",
        "                face_tensor = resize_with_padding(face_pil, TARGET_SIZE)\n",
        "                face_pil = T.ToPILImage()(face_tensor)\n",
        "\n",
        "                # Save face image\n",
        "                video_name = os.path.basename(video_path)\n",
        "                face_path = os.path.join(save_dir, f\"{video_name}_{frame_index}.jpg\")\n",
        "                face_pil.save(face_path)\n",
        "\n",
        "def extract_faces(video_path, save_dir, frames_per_video=10):\n",
        "    \"\"\"Extracts faces from a video and saves them as images.\"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Cannot open {video_path}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        step = max(1, frame_count // frames_per_video)\n",
        "\n",
        "        for i in range(0, frame_count, step):\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                continue\n",
        "\n",
        "            # Convert to RGB before face detection\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            pil_img = Image.fromarray(frame_rgb)\n",
        "\n",
        "            detect_and_save_faces(pil_img, i, video_path, save_dir)\n",
        "\n",
        "    finally:\n",
        "        cap.release()  # Ensure video file is released\n",
        "\n",
        "# Paths\n",
        "dataset_folder = \"/content/dataset\"\n",
        "video_folders = [\"Celeb-real\", \"Youtube-real\"]\n",
        "output_folder = os.path.join(dataset_folder, \"Preprocessed-images\", \"Celeb-real\")\n",
        "video_extensions = {\".mp4\", \".avi\", \".mov\", \".mkv\"}\n",
        "\n",
        "# Process all real videos sequentially (GPU optimized)\n",
        "video_files = []\n",
        "for folder in video_folders:\n",
        "    video_path = os.path.join(dataset_folder, folder)\n",
        "\n",
        "    if not os.path.exists(video_path):\n",
        "        print(f\"Skipping {folder}: Path does not exist!\")\n",
        "        continue\n",
        "\n",
        "    for video in os.listdir(video_path):\n",
        "        video_file = os.path.join(video_path, video)\n",
        "\n",
        "        output_check = os.path.join(output_folder, f\"{video}_0.jpg\")\n",
        "        if os.path.exists(output_check):\n",
        "            continue  # Skip if already processed\n",
        "\n",
        "        if os.path.isfile(video_file) and any(video.lower().endswith(ext) for ext in video_extensions):\n",
        "            video_files.append(video_file)\n",
        "\n",
        "print(f\"Total videos to process: {len(video_files)}\")\n",
        "\n",
        "# Process each video one by one (GPU optimized)\n",
        "for video_file in tqdm(video_files, desc=\"Processing Videos\"):\n",
        "    extract_faces(video_file, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssvjR55uJihQ",
        "outputId": "618cf601-8b75-478a-d530-2f0cf1bdb1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
            "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
            "find model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
            "set det-size: (640, 640)\n",
            "Total videos to process: 890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Videos: 100%|██████████| 890/890 [2:32:58<00:00, 10.31s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Define the source folder and output zip file\n",
        "source_folder = \"/content/dataset/Preprocessed-images/Celeb-real\"\n",
        "output_zip = \"/content/Celeb-real.zip\"\n",
        "\n",
        "# Create a zip file\n",
        "shutil.make_archive(output_zip.replace(\".zip\", \"\"), 'zip', source_folder)\n",
        "\n",
        "print(f\"Zipped folder saved as: {output_zip}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjU73aG_yVao",
        "outputId": "e1844b9e-b4d3-4abe-f15d-4dc08ab3aeeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zipped folder saved as: /content/Celeb-real.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/Celeb-real.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hiLRqJftybYe",
        "outputId": "56faaf5f-2363-41d2-e85e-797a8032092f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e08f6255-d8e1-4c13-b3ab-1c871eddbbf0\", \"Celeb-real.zip\", 65868602)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Do Not Execute\n",
        "## CNN code for face detection of CelebDF dataset of synthetic videos"
      ],
      "metadata": {
        "id": "09hTADpoeqnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import numpy as np\n",
        "from insightface.app import FaceAnalysis\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "# Check if MPS is available, else fallback to CPU\n",
        "device = torch.device(\"cpu\")  # Must use CPU due to MPS limitations\n",
        "\n",
        "# Initialize InsightFace RetinaFace\n",
        "face_detector = FaceAnalysis(name=\"buffalo_l\", providers=[\"CPUExecutionProvider\"])  # ✅ Load RetinaFace\n",
        "face_detector.prepare(ctx_id=-1)  # ✅ Run on CPU\n",
        "\n",
        "# Define target size (Xception requires 299x299)\n",
        "TARGET_SIZE = (299, 299)\n",
        "\n",
        "# Torchvision transform for resizing and padding\n",
        "def resize_with_padding(image, target_size):\n",
        "    \"\"\"Resize image while maintaining aspect ratio with padding (using PyTorch).\"\"\"\n",
        "    transform = T.Compose([\n",
        "        T.Resize(target_size, interpolation=T.InterpolationMode.BILINEAR),\n",
        "        T.CenterCrop(target_size),  # Ensures it remains square after resizing\n",
        "        T.ToTensor()\n",
        "    ])\n",
        "    return transform(image)\n",
        "\n",
        "def detect_and_save_faces(frames, frame_indices, video_path, save_dir):\n",
        "    \"\"\"Detect faces in a batch of frames using InsightFace RetinaFace and save cropped images.\"\"\"\n",
        "    for i, frame in enumerate(frames):\n",
        "        frame_np = np.array(frame)  # Convert PIL image to NumPy\n",
        "        h, w, _ = frame_np.shape\n",
        "\n",
        "        # Detect faces using InsightFace\n",
        "        faces = face_detector.get(frame_np)  # ✅ Correct method\n",
        "\n",
        "        if faces:  # Ensure at least one face is detected\n",
        "            for face in faces:\n",
        "                x1, y1, x2, y2 = face.bbox.astype(int)  # ✅ Correct way to get bounding box\n",
        "\n",
        "                # Ensure bounding box stays within frame\n",
        "                x1, y1 = max(0, x1), max(0, y1)\n",
        "                x2, y2 = min(w, x2), min(h, y2)\n",
        "\n",
        "                # Extract face region\n",
        "                if x2 > x1 and y2 > y1:\n",
        "                    face_crop = frame_np[y1:y2, x1:x2]\n",
        "                    face_pil = Image.fromarray(face_crop)\n",
        "\n",
        "                    # Resize while keeping aspect ratio\n",
        "                    face_tensor = resize_with_padding(face_pil, TARGET_SIZE)\n",
        "\n",
        "                    # Convert back to PIL for saving\n",
        "                    face_pil = T.ToPILImage()(face_tensor)\n",
        "\n",
        "                    # Save face image\n",
        "                    face_path = os.path.join(save_dir, f\"{os.path.basename(video_path)}_{frame_indices[i]}.jpg\")\n",
        "                    face_pil.save(face_path)\n",
        "\n",
        "def extract_faces(video_path, save_dir, frames_per_video=10, batch_size=4):\n",
        "    \"\"\"Extract faces from a video and save them as uniformly resized images.\"\"\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Cannot open {video_path}\")\n",
        "        return\n",
        "\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    step = max(1, frame_count // frames_per_video)\n",
        "\n",
        "    frame_batch = []\n",
        "    frame_indices = []\n",
        "\n",
        "    for i in range(0, frame_count, step):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            continue\n",
        "\n",
        "        # Convert to RGB before face detection\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        pil_img = Image.fromarray(frame_rgb)\n",
        "\n",
        "        frame_batch.append(pil_img)\n",
        "        frame_indices.append(i)\n",
        "\n",
        "        if len(frame_batch) >= batch_size:\n",
        "            detect_and_save_faces(frame_batch, frame_indices, video_path, save_dir)\n",
        "            frame_batch.clear()\n",
        "            frame_indices.clear()\n",
        "\n",
        "    if frame_batch:\n",
        "        detect_and_save_faces(frame_batch, frame_indices, video_path, save_dir)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "# Paths\n",
        "video_folder = os.path.abspath(\"CelebDF\")\n",
        "output_folder = \"Preprocessing\"\n",
        "video_extensions = {\".mp4\", \".avi\", \".mov\", \".mkv\"}\n",
        "\n",
        "# Process all videos\n",
        "for subfolder in os.listdir(video_folder):\n",
        "    subfolder_path = os.path.join(video_folder, subfolder)\n",
        "\n",
        "    if not os.path.isdir(subfolder_path):\n",
        "        continue\n",
        "\n",
        "    for video in tqdm(os.listdir(subfolder_path), desc=f\"Processing {subfolder}\", mininterval=2):\n",
        "        video_path = os.path.join(subfolder_path, video)\n",
        "\n",
        "        output_check = os.path.join(output_folder, f\"{video}_0.jpg\")\n",
        "        if os.path.exists(output_check):\n",
        "            continue\n",
        "\n",
        "        if os.path.isfile(video_path) and any(video.lower().endswith(ext) for ext in video_extensions):\n",
        "            extract_faces(video_path, output_folder)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jIgXWjZTenxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Delete Folder\n"
      ],
      "metadata": {
        "id": "5IyrX9E-dJcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "folder_path = \"/content/dataset/Preprocessed-images/Celeb-real\"  # Replace with the actual folder path\n",
        "\n",
        "shutil.rmtree(folder_path)  # Deletes the folder and all its contents\n",
        "\n",
        "print(f\"Deleted folder: {folder_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzDHBQczMjYv",
        "outputId": "a75628f0-b658-46b2-c0d9-49a525e1b5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted folder: /content/dataset/Preprocessed-images/Celeb-real\n"
          ]
        }
      ]
    }
  ]
}